{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dKPGRLe0JCCB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vr.programs\n",
    "from vr.preprocess import tokenize, encode, build_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_to_str(program, mode):\n",
    "    if mode == 'chain':\n",
    "        if not vr.programs.is_chain(program):\n",
    "            return None\n",
    "        return vr.programs.list_to_str(program)\n",
    "    elif mode == 'prefix':\n",
    "        program_prefix = vr.programs.list_to_prefix(program)\n",
    "        return vr.programs.list_to_str(program_prefix)\n",
    "    elif mode == 'postfix':\n",
    "        program_postfix = vr.programs.list_to_postfix(program)\n",
    "        return vr.programs.list_to_str(program_postfix)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(output_h5_file, questions, vocab):\n",
    "    print('Encoding data')\n",
    "    questions_encoded = []\n",
    "    programs_encoded = []\n",
    "    question_families = []\n",
    "    orig_idxs = []\n",
    "    image_idxs = []\n",
    "    answers = []\n",
    "    types = []\n",
    "\n",
    "    for orig_idx, q in enumerate(questions):\n",
    "        question = q['question']\n",
    "        if 'program' in q:\n",
    "            types += [q['program'][-1]['function']] # takes last program for a given input and the type of program\n",
    "        orig_idxs.append(orig_idx)\n",
    "        image_idxs.append(q['image_index'])\n",
    "        if 'question_family_index' in q:\n",
    "            question_families.append(q['question_family_index'])\n",
    "        question_tokens = tokenize(question,\n",
    "                            punct_to_keep=[';', ','],\n",
    "                            punct_to_remove=['?', '.'])\n",
    "        question_encoded = encode(question_tokens,\n",
    "                             vocab['question_token_to_idx'],\n",
    "                             allow_unk=encode_unk == 1)\n",
    "        questions_encoded.append(question_encoded)\n",
    "        if 'program' in q:\n",
    "            program = q['program']\n",
    "            program_str = program_to_str(program, mode)\n",
    "            program_tokens = tokenize(program_str)\n",
    "            program_encoded = encode(program_tokens, vocab['program_token_to_idx'])\n",
    "            programs_encoded.append(program_encoded)\n",
    "        if 'answer' in q:\n",
    "            answers.append(vocab['answer_token_to_idx'][q['answer']])\n",
    "\n",
    "    # Pad encoded questions and programs\n",
    "    max_question_length = max(len(x) for x in questions_encoded)\n",
    "    for qe in questions_encoded:\n",
    "        while len(qe) < max_question_length:\n",
    "            qe.append(vocab['question_token_to_idx']['<NULL>'])\n",
    "\n",
    "    if len(programs_encoded) > 0:\n",
    "        max_program_length = max(len(x) for x in programs_encoded)\n",
    "        for pe in programs_encoded:\n",
    "            while len(pe) < max_program_length:\n",
    "                pe.append(vocab['program_token_to_idx']['<NULL>'])\n",
    "                \n",
    "    print('Writing output')\n",
    "    questions_encoded = np.asarray(questions_encoded, dtype=np.int32)\n",
    "    programs_encoded = np.asarray(programs_encoded, dtype=np.int32)\n",
    "    print(questions_encoded.shape)\n",
    "    print(programs_encoded.shape)\n",
    "    \n",
    "    mapping = {}\n",
    "    for i, t in enumerate(set(types)):\n",
    "        mapping[t] = i\n",
    "    print(mapping)\n",
    "    types_coded = []\n",
    "    for t in types:\n",
    "        types_coded += [mapping[t]]\n",
    "    \n",
    "    with h5py.File(output_h5_file, 'w') as f:\n",
    "        f.create_dataset('questions', data=questions_encoded)\n",
    "        f.create_dataset('image_idxs', data=np.asarray(image_idxs))\n",
    "        f.create_dataset('orig_idxs', data=np.asarray(orig_idxs))\n",
    "\n",
    "        if len(programs_encoded) > 0:\n",
    "            f.create_dataset('programs', data=programs_encoded)\n",
    "        if len(question_families) > 0:\n",
    "            f.create_dataset('question_families', data=np.asarray(question_families))\n",
    "        if len(answers) > 0:\n",
    "            f.create_dataset('answers', data=np.asarray(answers))\n",
    "        if len(types) > 0:\n",
    "            f.create_dataset('types', data=np.asarray(types_coded))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(output_h5_file, input_questions_json, input_vocab_json='', output_vocab_json=''):\n",
    "    \n",
    "    if (input_vocab_json == '') and (output_vocab_json == ''):\n",
    "        print('Must give one of --input_vocab_json or --output_vocab_json')\n",
    "        return\n",
    "    \n",
    "    print('Loading data')\n",
    "    with open(input_questions_json, 'r') as f:\n",
    "        questions = json.load(f)['questions']\n",
    "        \n",
    "    if input_vocab_json == '' or expand_vocab == 1:\n",
    "        print('Building vocab')\n",
    "        if 'answer' in questions[0]:\n",
    "            answer_token_to_idx = build_vocab(\n",
    "                (q['answer'] for q in questions)\n",
    "            )\n",
    "        question_token_to_idx = build_vocab(\n",
    "            (q['question'] for q in questions),\n",
    "            min_token_count=unk_threshold,\n",
    "            punct_to_keep=[';', ','], punct_to_remove=['?', '.']\n",
    "        )\n",
    "        all_program_strs = []\n",
    "        for q in questions:\n",
    "            if 'program' not in q: continue\n",
    "            program_str = program_to_str(q['program'], mode)\n",
    "            if program_str is not None:\n",
    "                all_program_strs.append(program_str)\n",
    "        program_token_to_idx = build_vocab(all_program_strs)\n",
    "        vocab = {\n",
    "            'question_token_to_idx': question_token_to_idx,\n",
    "            'program_token_to_idx': program_token_to_idx,\n",
    "            'answer_token_to_idx': answer_token_to_idx,\n",
    "        }\n",
    "    \n",
    "    if input_vocab_json != '':\n",
    "        print('Loading vocab')\n",
    "        if expand_vocab == 1:\n",
    "            new_vocab = vocab\n",
    "        with open(input_vocab_json, 'r') as f:\n",
    "            vocab = json.load(f)\n",
    "        if expand_vocab == 1:\n",
    "            num_new_words = 0\n",
    "            for word in new_vocab['question_token_to_idx']:\n",
    "                if word not in vocab['question_token_to_idx']:\n",
    "                    print('Found new word %s' % word)\n",
    "                    idx = len(vocab['question_token_to_idx'])\n",
    "                    vocab['question_token_to_idx'][word] = idx\n",
    "                    num_new_words += 1\n",
    "            print('Found %d new words' % num_new_words)\n",
    "\n",
    "    \n",
    "    if output_vocab_json != '':\n",
    "        with open(output_vocab_json, 'w') as f:\n",
    "            json.dump(vocab, f)\n",
    "            \n",
    "    encode_data(output_h5_file, questions, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================== Args =========================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'prefix'\n",
    "expand_vocab = 0\n",
    "unk_threshold = 1\n",
    "encode_unk = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1HOeL1jyJWNr"
   },
   "outputs": [],
   "source": [
    "train_questions_path = 'data/CLEVR_v1.0/questions/CLEVR_train_questions.json'\n",
    "valid_questions_path = 'data/CLEVR_v1.0/questions/CLEVR_val_questions.json'\n",
    "test_questions_path = 'data/CLEVR_v1.0/questions/CLEVR_test_questions.json'\n",
    "\n",
    "train_output_h5_file = 'data/train_questions.h5'\n",
    "val_output_h5_file = 'data/val_questions.h5'\n",
    "test_output_h5_file = 'data/test_questions.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea3BiiV2hies"
   },
   "source": [
    "**====================================================== Main =========================================================**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Building vocab\n",
      "Encoding data\n",
      "Writing output\n",
      "(699989, 46)\n",
      "(699989, 27)\n",
      "{'count': 0, 'equal_size': 1, 'exist': 2, 'equal_material': 3, 'query_material': 4, 'greater_than': 5, 'equal_integer': 6, 'equal_shape': 7, 'equal_color': 8, 'less_than': 9, 'query_color': 10, 'query_shape': 11, 'query_size': 12}\n",
      "Loading data\n",
      "Loading vocab\n",
      "Encoding data\n",
      "Writing output\n",
      "(149991, 46)\n",
      "(149991, 27)\n",
      "{'query_size': 0, 'count': 1, 'equal_size': 2, 'exist': 3, 'equal_material': 4, 'query_material': 5, 'greater_than': 6, 'equal_integer': 7, 'equal_shape': 8, 'equal_color': 9, 'query_color': 10, 'query_shape': 11, 'less_than': 12}\n",
      "Loading data\n",
      "Loading vocab\n",
      "Encoding data\n",
      "Writing output\n",
      "(149988, 45)\n",
      "(0,)\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "preprocess(train_output_h5_file, train_questions_path, output_vocab_json='data/vocab.json')\n",
    "preprocess(val_output_h5_file, valid_questions_path, input_vocab_json='data/vocab.json')\n",
    "preprocess(test_output_h5_file, test_questions_path, input_vocab_json='data/vocab.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding Programs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any other things that are the same shape as the big metallic object?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [1], 'function': 'filter_material', 'value_inputs': ['metal']}, {'inputs': [2], 'function': 'unique', 'value_inputs': []}, {'inputs': [3], 'function': 'same_shape', 'value_inputs': []}, {'inputs': [4], 'function': 'exist', 'value_inputs': []}]\n",
      "exist same_shape unique filter_material[metal] filter_size[large] scene\n",
      "['<START>', 'exist', 'same_shape', 'unique', 'filter_material[metal]', 'filter_size[large]', 'scene', '<END>']\n",
      "[1, 10, 39, 43, 19, 24, 41, 2]\n",
      "\n",
      "['no']\n",
      "Is there a big brown object of the same shape as the green thing?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_color', 'value_inputs': ['green']}, {'inputs': [1], 'function': 'unique', 'value_inputs': []}, {'inputs': [2], 'function': 'same_shape', 'value_inputs': []}, {'inputs': [3], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [4], 'function': 'filter_color', 'value_inputs': ['brown']}, {'inputs': [5], 'function': 'exist', 'value_inputs': []}]\n",
      "exist filter_color[brown] filter_size[large] same_shape unique filter_color[green] scene\n",
      "['<START>', 'exist', 'filter_color[brown]', 'filter_size[large]', 'same_shape', 'unique', 'filter_color[green]', 'scene', '<END>']\n",
      "[1, 10, 12, 24, 39, 43, 15, 41, 2]\n",
      "\n",
      "['yes']\n",
      "What is the material of the big purple object?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [1], 'function': 'filter_color', 'value_inputs': ['purple']}, {'inputs': [2], 'function': 'unique', 'value_inputs': []}, {'inputs': [3], 'function': 'query_material', 'value_inputs': []}]\n",
      "query_material unique filter_color[purple] filter_size[large] scene\n",
      "['<START>', 'query_material', 'unique', 'filter_color[purple]', 'filter_size[large]', 'scene', '<END>']\n",
      "[1, 30, 43, 16, 24, 41, 2]\n",
      "\n",
      "['metal']\n",
      "There is a small gray block; are there any spheres to the left of it?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['small']}, {'inputs': [1], 'function': 'filter_color', 'value_inputs': ['gray']}, {'inputs': [2], 'function': 'filter_shape', 'value_inputs': ['cube']}, {'inputs': [3], 'function': 'unique', 'value_inputs': []}, {'inputs': [4], 'function': 'relate', 'value_inputs': ['left']}, {'inputs': [5], 'function': 'filter_shape', 'value_inputs': ['sphere']}, {'inputs': [6], 'function': 'exist', 'value_inputs': []}]\n",
      "exist filter_shape[sphere] relate[left] unique filter_shape[cube] filter_color[gray] filter_size[small] scene\n",
      "['<START>', 'exist', 'filter_shape[sphere]', 'relate[left]', 'unique', 'filter_shape[cube]', 'filter_color[gray]', 'filter_size[small]', 'scene', '<END>']\n",
      "[1, 10, 23, 35, 43, 21, 14, 25, 41, 2]\n",
      "\n",
      "['yes']\n",
      "Is the purple thing the same shape as the large gray rubber thing?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_color', 'value_inputs': ['purple']}, {'inputs': [1], 'function': 'unique', 'value_inputs': []}, {'inputs': [2], 'function': 'query_shape', 'value_inputs': []}, {'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [4], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [5], 'function': 'filter_color', 'value_inputs': ['gray']}, {'inputs': [6], 'function': 'filter_material', 'value_inputs': ['rubber']}, {'inputs': [7], 'function': 'unique', 'value_inputs': []}, {'inputs': [8], 'function': 'query_shape', 'value_inputs': []}, {'inputs': [3, 9], 'function': 'equal_shape', 'value_inputs': []}]\n",
      "equal_shape query_shape unique filter_color[purple] scene query_shape unique filter_material[rubber] filter_color[gray] filter_size[large] scene\n",
      "['<START>', 'equal_shape', 'query_shape', 'unique', 'filter_color[purple]', 'scene', 'query_shape', 'unique', 'filter_material[rubber]', 'filter_color[gray]', 'filter_size[large]', 'scene', '<END>']\n",
      "[1, 8, 31, 43, 16, 41, 31, 43, 20, 14, 24, 41, 2]\n",
      "\n",
      "['no']\n",
      "What number of other objects are the same size as the purple shiny object?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_color', 'value_inputs': ['purple']}, {'inputs': [1], 'function': 'filter_material', 'value_inputs': ['metal']}, {'inputs': [2], 'function': 'unique', 'value_inputs': []}, {'inputs': [3], 'function': 'same_size', 'value_inputs': []}, {'inputs': [4], 'function': 'count', 'value_inputs': []}]\n",
      "count same_size unique filter_material[metal] filter_color[purple] scene\n",
      "['<START>', 'count', 'same_size', 'unique', 'filter_material[metal]', 'filter_color[purple]', 'scene', '<END>']\n",
      "[1, 4, 40, 43, 19, 16, 41, 2]\n",
      "\n",
      "['2']\n",
      "How many objects are either metal things behind the small green rubber cylinder or small green rubber objects?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['small']}, {'inputs': [1], 'function': 'filter_color', 'value_inputs': ['green']}, {'inputs': [2], 'function': 'filter_material', 'value_inputs': ['rubber']}, {'inputs': [3], 'function': 'filter_shape', 'value_inputs': ['cylinder']}, {'inputs': [4], 'function': 'unique', 'value_inputs': []}, {'inputs': [5], 'function': 'relate', 'value_inputs': ['behind']}, {'inputs': [6], 'function': 'filter_material', 'value_inputs': ['metal']}, {'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [8], 'function': 'filter_size', 'value_inputs': ['small']}, {'inputs': [9], 'function': 'filter_color', 'value_inputs': ['green']}, {'inputs': [10], 'function': 'filter_material', 'value_inputs': ['rubber']}, {'inputs': [7, 11], 'function': 'union', 'value_inputs': []}, {'inputs': [12], 'function': 'count', 'value_inputs': []}]\n",
      "count union filter_material[metal] relate[behind] unique filter_shape[cylinder] filter_material[rubber] filter_color[green] filter_size[small] scene filter_material[rubber] filter_color[green] filter_size[small] scene\n",
      "['<START>', 'count', 'union', 'filter_material[metal]', 'relate[behind]', 'unique', 'filter_shape[cylinder]', 'filter_material[rubber]', 'filter_color[green]', 'filter_size[small]', 'scene', 'filter_material[rubber]', 'filter_color[green]', 'filter_size[small]', 'scene', '<END>']\n",
      "[1, 4, 42, 19, 33, 43, 22, 20, 15, 25, 41, 20, 15, 25, 41, 2]\n",
      "\n",
      "['2']\n",
      "What is the color of the large shiny sphere?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [1], 'function': 'filter_material', 'value_inputs': ['metal']}, {'inputs': [2], 'function': 'filter_shape', 'value_inputs': ['sphere']}, {'inputs': [3], 'function': 'unique', 'value_inputs': []}, {'inputs': [4], 'function': 'query_color', 'value_inputs': []}]\n",
      "query_color unique filter_shape[sphere] filter_material[metal] filter_size[large] scene\n",
      "['<START>', 'query_color', 'unique', 'filter_shape[sphere]', 'filter_material[metal]', 'filter_size[large]', 'scene', '<END>']\n",
      "[1, 29, 43, 23, 19, 24, 41, 2]\n",
      "\n",
      "['purple']\n",
      "What is the thing in front of the small metallic object made of?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_size', 'value_inputs': ['small']}, {'inputs': [1], 'function': 'filter_material', 'value_inputs': ['metal']}, {'inputs': [2], 'function': 'unique', 'value_inputs': []}, {'inputs': [3], 'function': 'relate', 'value_inputs': ['front']}, {'inputs': [4], 'function': 'unique', 'value_inputs': []}, {'inputs': [5], 'function': 'query_material', 'value_inputs': []}]\n",
      "query_material unique relate[front] unique filter_material[metal] filter_size[small] scene\n",
      "['<START>', 'query_material', 'unique', 'relate[front]', 'unique', 'filter_material[metal]', 'filter_size[small]', 'scene', '<END>']\n",
      "[1, 30, 43, 34, 43, 19, 25, 41, 2]\n",
      "\n",
      "['rubber']\n",
      "Does the green rubber object have the same shape as the gray thing that is on the right side of the big purple object?\n",
      "[{'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [0], 'function': 'filter_color', 'value_inputs': ['green']}, {'inputs': [1], 'function': 'filter_material', 'value_inputs': ['rubber']}, {'inputs': [2], 'function': 'unique', 'value_inputs': []}, {'inputs': [3], 'function': 'query_shape', 'value_inputs': []}, {'inputs': [], 'function': 'scene', 'value_inputs': []}, {'inputs': [5], 'function': 'filter_size', 'value_inputs': ['large']}, {'inputs': [6], 'function': 'filter_color', 'value_inputs': ['purple']}, {'inputs': [7], 'function': 'unique', 'value_inputs': []}, {'inputs': [8], 'function': 'relate', 'value_inputs': ['right']}, {'inputs': [9], 'function': 'filter_color', 'value_inputs': ['gray']}, {'inputs': [10], 'function': 'unique', 'value_inputs': []}, {'inputs': [11], 'function': 'query_shape', 'value_inputs': []}, {'inputs': [4, 12], 'function': 'equal_shape', 'value_inputs': []}]\n",
      "equal_shape query_shape unique filter_material[rubber] filter_color[green] scene query_shape unique filter_color[gray] relate[right] unique filter_color[purple] filter_size[large] scene\n",
      "['<START>', 'equal_shape', 'query_shape', 'unique', 'filter_material[rubber]', 'filter_color[green]', 'scene', 'query_shape', 'unique', 'filter_color[gray]', 'relate[right]', 'unique', 'filter_color[purple]', 'filter_size[large]', 'scene', '<END>']\n",
      "[1, 8, 31, 43, 20, 15, 41, 31, 43, 14, 36, 43, 16, 24, 41, 2]\n",
      "\n",
      "['no']\n"
     ]
    }
   ],
   "source": [
    "with open('data/vocab.json', 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "with open('data/CLEVR_v1.0/questions/CLEVR_val_questions.json', 'r') as f:\n",
    "    questions = json.load(f)['questions']\n",
    "    for i, q in enumerate(questions):\n",
    "        if 'program' not in q: continue\n",
    "        print(q['question'])\n",
    "        print(q['program'])\n",
    "        program_str = program_to_str(q['program'], mode)\n",
    "        if program_str is not None:\n",
    "            print(program_str)\n",
    "        program_tokens = tokenize(program_str)\n",
    "        print(program_tokens)\n",
    "        program_encoded = encode(program_tokens, vocab['program_token_to_idx'])\n",
    "        print(program_encoded)\n",
    "        print()\n",
    "        if 'answer' in q:\n",
    "            print([q['answer']])\n",
    "        if i == 9: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
