{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a96e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import ipdb as pdb\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from termcolor import colored\n",
    "import time\n",
    "\n",
    "import torch\n",
    "torch.backends.cudnn.enabled = True\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import vr.utils as utils\n",
    "import vr.preprocess\n",
    "from vr.data import ClevrDataset, ClevrDataLoader\n",
    "from vr.models.module_net import ModuleNet\n",
    "from vr.models.seq2seq import Seq2Seq\n",
    "from vr.models.baselines import LstmModel, CnnLstmModel, CnnLstmSaModel\n",
    "from vr.models.filmed_net import FiLMedNet\n",
    "from vr.models.film_gen import FiLMGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fdb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_int_list(s):\n",
    "    if s == '': return ()\n",
    "    return tuple(int(n) for n in s.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6426eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(m):\n",
    "    if m is None:\n",
    "        return None\n",
    "    state = {}\n",
    "    for k, v in m.state_dict().items():\n",
    "        state[k] = v.clone()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4400be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_program_generator():\n",
    "    vocab = utils.load_vocab(vocab_json)\n",
    "    if program_generator_start_from is not None:\n",
    "        pg, kwargs = utils.load_program_generator(\n",
    "            program_generator_start_from, model_type=model_type)\n",
    "        cur_vocab_size = pg.encoder_embed.weight.size(0)\n",
    "        if cur_vocab_size != len(vocab['question_token_to_idx']):\n",
    "            print('Expanding vocabulary of program generator')\n",
    "            pg.expand_encoder_vocab(vocab['question_token_to_idx'])\n",
    "            kwargs['encoder_vocab_size'] = len(vocab['question_token_to_idx'])\n",
    "    else:\n",
    "        kwargs = {\n",
    "            'encoder_vocab_size': len(vocab['question_token_to_idx']),\n",
    "            'decoder_vocab_size': len(vocab['program_token_to_idx']),\n",
    "            'wordvec_dim': rnn_wordvec_dim,\n",
    "            'hidden_dim': rnn_hidden_dim,\n",
    "            'rnn_num_layers': rnn_num_layers,\n",
    "            'rnn_dropout': rnn_dropout,\n",
    "        }\n",
    "        if model_type == 'FiLM':\n",
    "            kwargs['parameter_efficient'] = program_generator_parameter_efficient == 1\n",
    "            kwargs['output_batchnorm'] = rnn_output_batchnorm == 1\n",
    "            kwargs['bidirectional'] = bidirectional == 1\n",
    "            kwargs['encoder_type'] = encoder_type\n",
    "            kwargs['decoder_type'] = decoder_type\n",
    "            kwargs['gamma_option'] = gamma_option\n",
    "            kwargs['gamma_baseline'] = gamma_baseline\n",
    "            kwargs['num_modules'] = num_modules\n",
    "            kwargs['module_num_layers'] = module_num_layers\n",
    "            kwargs['module_dim'] = module_dim\n",
    "            kwargs['debug_every'] = debug_every\n",
    "            pg = FiLMGen(**kwargs)\n",
    "        else:\n",
    "            pg = Seq2Seq(**kwargs)\n",
    "    pg.cuda()\n",
    "    pg.train()\n",
    "    return pg, kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5744c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_engine():\n",
    "    vocab = utils.load_vocab(vocab_json)\n",
    "    if execution_engine_start_from is not None:\n",
    "        ee, kwargs = utils.load_execution_engine(\n",
    "            execution_engine_start_from, model_type=model_type)\n",
    "    else:\n",
    "        kwargs = {\n",
    "            'vocab': vocab,\n",
    "            'feature_dim': parse_int_list(feature_dim),\n",
    "            'stem_batchnorm': module_stem_batchnorm == 1,\n",
    "            'stem_num_layers': module_stem_num_layers,\n",
    "            'module_dim': module_dim,\n",
    "            'module_residual': module_residual == 1,\n",
    "            'module_batchnorm': module_batchnorm == 1,\n",
    "            'classifier_proj_dim': classifier_proj_dim,\n",
    "            'classifier_downsample': classifier_downsample,\n",
    "            'classifier_fc_layers': parse_int_list(classifier_fc_dims),\n",
    "            'classifier_batchnorm': classifier_batchnorm == 1,\n",
    "            'classifier_dropout': classifier_dropout,\n",
    "        }\n",
    "        if model_type == 'FiLM':\n",
    "            kwargs['num_modules'] = num_modules\n",
    "            kwargs['stem_kernel_size'] = module_stem_kernel_size\n",
    "            kwargs['stem_stride'] = module_stem_stride\n",
    "            kwargs['stem_padding'] = module_stem_padding\n",
    "            kwargs['module_num_layers'] = module_num_layers\n",
    "            kwargs['module_batchnorm_affine'] = module_batchnorm_affine == 1\n",
    "            kwargs['module_dropout'] = module_dropout\n",
    "            kwargs['module_input_proj'] = module_input_proj\n",
    "            kwargs['module_kernel_size'] = module_kernel_size\n",
    "            kwargs['use_gamma'] = use_gamma == 1\n",
    "            kwargs['use_beta'] = use_beta == 1\n",
    "            kwargs['use_coords'] = use_coords\n",
    "            kwargs['debug_every'] = debug_every\n",
    "            kwargs['print_verbose_every'] = print_verbose_every\n",
    "            kwargs['condition_method'] = condition_method\n",
    "            kwargs['condition_pattern'] = parse_int_list(condition_pattern)\n",
    "            ee = FiLMedNet(**kwargs)\n",
    "        else:\n",
    "            ee = ModuleNet(**kwargs)\n",
    "    ee.cuda()\n",
    "    ee.train()\n",
    "    return ee, kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d472879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_mode(mode, models):\n",
    "    assert mode in ['train', 'eval']\n",
    "    for m in models:\n",
    "        if m is None: continue\n",
    "        if mode == 'train': m.train()\n",
    "        if mode == 'eval': m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabd2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(program_generator, execution_engine, baseline_model, loader):\n",
    "    set_mode('eval', [program_generator, execution_engine, baseline_model])\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for batch in loader:\n",
    "        questions, _, feats, answers, programs, _ = batch\n",
    "        if isinstance(questions, list):\n",
    "            questions = questions[0]\n",
    "\n",
    "        questions_var = Variable(questions.cuda())\n",
    "        feats_var = Variable(feats.cuda())\n",
    "        answers_var = Variable(feats.cuda())\n",
    "        if programs[0] is not None:\n",
    "            programs_var = Variable(programs.cuda())\n",
    "\n",
    "        scores = None  # Use this for everything but PG\n",
    "        if model_type == 'PG':\n",
    "            vocab = utils.load_vocab(vocab_json)\n",
    "            for i in range(questions.size(0)):\n",
    "                program_pred = program_generator.sample(Variable(questions[i:i+1].cuda(), volatile=True))\n",
    "                program_pred_str = vr.preprocess.decode(program_pred, vocab['program_idx_to_token'])\n",
    "                program_str = vr.preprocess.decode(programs[i], vocab['program_idx_to_token'])\n",
    "                if program_pred_str == program_str:\n",
    "                    num_correct += 1\n",
    "                num_samples += 1\n",
    "        elif model_type == 'EE':\n",
    "            scores = execution_engine(feats_var, programs_var)\n",
    "        elif model_type == 'PG+EE':\n",
    "            programs_pred = program_generator.reinforce_sample(\n",
    "                questions_var, argmax=True)\n",
    "            scores = execution_engine(feats_var, programs_pred)\n",
    "        elif model_type == 'FiLM':\n",
    "            programs_pred = program_generator(questions_var)\n",
    "            scores = execution_engine(feats_var, programs_pred)\n",
    "        elif model_type in ['LSTM', 'CNN+LSTM', 'CNN+LSTM+SA']:\n",
    "            scores = baseline_model(questions_var, feats_var)\n",
    "\n",
    "        if scores is not None:\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            num_correct += (preds == answers).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "        if num_val_samples is not None and num_samples >= num_val_samples:\n",
    "            break\n",
    "\n",
    "    set_mode('train', [program_generator, execution_engine, baseline_model])\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a80d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grad_num_nans(model, model_name='model'):\n",
    "    grads = [p.grad for p in model.parameters() if p.grad is not None]\n",
    "    num_nans = [np.sum(np.isnan(grad.data.cpu().numpy())) for grad in grads]\n",
    "    nan_checks = [num_nan == 0 for num_nan in num_nans]\n",
    "    if False in nan_checks:\n",
    "        print('Nans in ' + model_name + ' gradient!')\n",
    "        print(num_nans)\n",
    "        pdb.set_trace()\n",
    "        raise(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b38130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader, val_loader):\n",
    "    vocab = utils.load_vocab(vocab_json)\n",
    "    program_generator, pg_kwargs, pg_optimizer = None, None, None\n",
    "    execution_engine, ee_kwargs, ee_optimizer = None, None, None\n",
    "    baseline_model, baseline_kwargs, baseline_optimizer = None, None, None\n",
    "    baseline_type = None\n",
    "\n",
    "    pg_best_state, ee_best_state, baseline_best_state = None, None, None\n",
    "    \n",
    "    optim_method = getattr(torch.optim, optimizer)\n",
    "    \n",
    "    if model_type in ['FiLM', 'PG', 'PG+EE']:\n",
    "        program_generator, pg_kwargs = get_program_generator()\n",
    "        pg_optimizer = optim_method(program_generator.parameters(),\n",
    "                                    lr=learning_rate,\n",
    "                                    weight_decay=weight_decay)\n",
    "        print('Here is the conditioning network:')\n",
    "        print(program_generator)\n",
    "    \n",
    "    if model_type in ['FiLM', 'EE', 'PG+EE']:\n",
    "        execution_engine, ee_kwargs = get_execution_engine()\n",
    "        ee_optimizer = optim_method(execution_engine.parameters(),\n",
    "                                    lr=learning_rate,\n",
    "                                    weight_decay=weight_decay)\n",
    "        print('Here is the conditioned network:')\n",
    "        print(execution_engine)\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "    stats = {\n",
    "        'train_losses': [],\n",
    "        'train_rewards': [],\n",
    "        'train_losses_ts': [],\n",
    "        'train_accs': [],\n",
    "        'val_accs': [],\n",
    "        'val_accs_ts': [],\n",
    "        'best_val_acc': -1,\n",
    "        'model_t': 0,\n",
    "    }\n",
    "    \n",
    "    t, epoch, reward_moving_average = 0, 0, 0\n",
    "    \n",
    "    set_mode('train', [program_generator, execution_engine, baseline_model])\n",
    "    \n",
    "    print('train_loader has %d samples' % len(train_loader.dataset))\n",
    "    print('val_loader has %d samples' % len(val_loader.dataset))\n",
    "\n",
    "    num_checkpoints = 0\n",
    "    epoch_start_time = 0.0\n",
    "    epoch_total_time = 0.0\n",
    "    train_pass_total_time = 0.0\n",
    "    val_pass_total_time = 0.0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    while t < num_iterations:\n",
    "        if (epoch > 0) and (use_time == 1):\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            epoch_total_time += epoch_time\n",
    "            print(colored('EPOCH PASS AVG TIME: ' + str(epoch_total_time / epoch), 'white'))\n",
    "            print(colored('Epoch Pass Time      : ' + str(epoch_time), 'white'))\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        epoch += 1\n",
    "        print('Starting epoch %d' % epoch)\n",
    "        for batch in train_loader:\n",
    "            t += 1\n",
    "            questions, _, feats, answers, programs, _ = batch\n",
    "            if isinstance(questions, list):\n",
    "                questions = questions[0]\n",
    "            questions_var = Variable(questions.cuda())\n",
    "            feats_var = Variable(feats.cuda())\n",
    "            answers_var = Variable(answers.cuda())\n",
    "            if programs[0] is not None:\n",
    "                programs_var = Variable(programs.cuda())\n",
    "            reward = None\n",
    "\n",
    "            if model_type == 'FiLM':\n",
    "                if set_execution_engine_eval == 1:\n",
    "                    set_mode('eval', [execution_engine])\n",
    "                programs_pred = program_generator(questions_var)\n",
    "                scores = execution_engine(feats_var, programs_pred)\n",
    "                loss = loss_fn(scores, answers_var)\n",
    "\n",
    "                pg_optimizer.zero_grad()\n",
    "                ee_optimizer.zero_grad()\n",
    "\n",
    "                if debug_every <= -2:\n",
    "                    pdb.set_trace()\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if debug_every < float('inf'):\n",
    "                    check_grad_num_nans(execution_engine, 'FiLMedNet')\n",
    "                    check_grad_num_nans(program_generator, 'FiLMGen')\n",
    "\n",
    "                if train_program_generator == 1:\n",
    "                    if grad_clip > 0:\n",
    "                        torch.nn.utils.clip_grad_norm(program_generator.parameters(), grad_clip)\n",
    "                    pg_optimizer.step()\n",
    "                if train_execution_engine == 1:\n",
    "                    if grad_clip > 0:\n",
    "                        torch.nn.utils.clip_grad_norm(execution_engine.parameters(), grad_clip)\n",
    "                    ee_optimizer.step()\n",
    "\n",
    "            if t % record_loss_every == 0:\n",
    "                running_loss += loss.item()\n",
    "                avg_loss = running_loss / record_loss_every\n",
    "                print(t, avg_loss)\n",
    "                stats['train_losses'].append(avg_loss)\n",
    "                stats['train_losses_ts'].append(t)\n",
    "                if reward is not None:\n",
    "                    stats['train_rewards'].append(reward)\n",
    "                running_loss = 0.0\n",
    "            else:\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            if t % checkpoint_every == 0:\n",
    "                num_checkpoints += 1\n",
    "                print('Checking training accuracy ... ')\n",
    "                start = time.time()\n",
    "                with torch.no_grad():\n",
    "                    train_acc = check_accuracy(program_generator, execution_engine,\n",
    "                                               baseline_model, train_loader)\n",
    "                if use_time == 1:\n",
    "                    train_pass_time = (time.time() - start)\n",
    "                    train_pass_total_time += train_pass_time\n",
    "                    print(colored('TRAIN PASS AVG TIME: ' + str(train_pass_total_time / num_checkpoints), 'red'))\n",
    "                    print(colored('Train Pass Time      : ' + str(train_pass_time), 'red'))\n",
    "                print('train accuracy is', train_acc)\n",
    "                print('Checking validation accuracy ...')\n",
    "                start = time.time()\n",
    "                with torch.no_grad():\n",
    "                    val_acc = check_accuracy(program_generator, execution_engine,\n",
    "                                             baseline_model, val_loader)\n",
    "                if use_time == 1:\n",
    "                    val_pass_time = (time.time() - start)\n",
    "                    val_pass_total_time += val_pass_time\n",
    "                    print(colored('VAL PASS AVG TIME:   ' + str(val_pass_total_time / num_checkpoints), 'cyan'))\n",
    "                    print(colored('Val Pass Time        : ' + str(val_pass_time), 'cyan'))\n",
    "                print('val accuracy is ', val_acc)\n",
    "                stats['train_accs'].append(train_acc)\n",
    "                stats['val_accs'].append(val_acc)\n",
    "                stats['val_accs_ts'].append(t)\n",
    "\n",
    "                if val_acc > stats['best_val_acc']:\n",
    "                    stats['best_val_acc'] = val_acc\n",
    "                    stats['model_t'] = t\n",
    "                    best_pg_state = get_state(program_generator)\n",
    "                    best_ee_state = get_state(execution_engine)\n",
    "                    best_baseline_state = get_state(baseline_model)\n",
    "\n",
    "                checkpoint = {\n",
    "#                     'args': args.__dict__,\n",
    "                    'program_generator_kwargs': pg_kwargs,\n",
    "                    'program_generator_state': best_pg_state,\n",
    "                    'execution_engine_kwargs': ee_kwargs,\n",
    "                    'execution_engine_state': best_ee_state,\n",
    "                    'baseline_kwargs': baseline_kwargs,\n",
    "                    'baseline_state': best_baseline_state,\n",
    "                    'baseline_type': baseline_type,\n",
    "                    'vocab': vocab\n",
    "                }\n",
    "\n",
    "                for k, v in stats.items():\n",
    "                    checkpoint[k] = v\n",
    "                print('Saving checkpoint to %s' % checkpoint_path)\n",
    "                torch.save(checkpoint, checkpoint_path)\n",
    "                del checkpoint['program_generator_state']\n",
    "                del checkpoint['execution_engine_state']\n",
    "                del checkpoint['baseline_state']\n",
    "                with open(checkpoint_path + '.json', 'w') as f:\n",
    "                    json.dump(checkpoint, f)\n",
    "\n",
    "            if t == num_iterations:\n",
    "                break\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c451b7ad",
   "metadata": {},
   "source": [
    "**===================================================== Args ===========================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2459e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "train_questions_h5 = 'data/train_questions.h5'\n",
    "train_features_h5 = 'data/train_features.h5'\n",
    "val_questions_h5 = 'data/val_questions.h5'\n",
    "val_features_h5 = 'data/val_features.h5'\n",
    "feature_dim = '1024,14,14'\n",
    "vocab_json = 'data/vocab.json'\n",
    "\n",
    "loader_num_workers = 1\n",
    "use_local_copies = 0\n",
    "cleanup_local_copies = 1\n",
    "\n",
    "family_split_file = None\n",
    "num_train_samples = None\n",
    "num_val_samples = 149991\n",
    "shuffle_train_data = 1\n",
    "\n",
    "# What type of model to use and which parts to train\n",
    "model_type = 'FiLM'\n",
    "#   choices=['FiLM', 'PG', 'EE', 'PG+EE', 'LSTM', 'CNN+LSTM', 'CNN+LSTM+SA']\n",
    "train_program_generator = 1\n",
    "train_execution_engine = 1\n",
    "baseline_train_only_rnn = 0\n",
    "\n",
    "# Start from an existing checkpoint\n",
    "program_generator_start_from = None\n",
    "execution_engine_start_from = None\n",
    "baseline_start_from = None\n",
    "\n",
    "# RNN options\n",
    "rnn_wordvec_dim = 200\n",
    "rnn_hidden_dim = 4096\n",
    "rnn_num_layers = 1\n",
    "rnn_dropout = 0\n",
    "\n",
    "# Module net / FiLMedNet options\n",
    "module_stem_num_layers = 1\n",
    "module_stem_batchnorm = 1\n",
    "module_dim = 128\n",
    "module_residual = 1\n",
    "module_batchnorm = 1\n",
    "\n",
    "# FiLM only options\n",
    "set_execution_engine_eval = 0\n",
    "program_generator_parameter_efficient = 1\n",
    "rnn_output_batchnorm = 0\n",
    "bidirectional = 0\n",
    "encoder_type = 'gru' \n",
    "#   choices=['linear', 'gru', 'lstm'])\n",
    "decoder_type = 'linear' \n",
    "#   choices=['linear', 'gru', 'lstm'])\n",
    "gamma_option = 'linear' \n",
    "#   choices=['linear', 'sigmoid', 'tanh', 'exp'])\n",
    "gamma_baseline = 1\n",
    "num_modules = 4\n",
    "module_stem_kernel_size = 3\n",
    "module_stem_stride = 1\n",
    "module_stem_padding = None\n",
    "module_num_layers = 1  # Only mnl=1 currently implemented\n",
    "module_batchnorm_affine = 0  # 1 overrides other factors\n",
    "module_dropout = 0e-2\n",
    "module_input_proj = 1  # Inp conv kernel size (0 for None)\n",
    "module_kernel_size = 3\n",
    "condition_method = 'bn-film' \n",
    "#   choices=['block-input-film', 'block-output-film', 'bn-film', 'concat', 'conv-film', 'relu-film'])\n",
    "condition_pattern = '1,1,1,1'  # List of 0/1's (len = # FiLMs)\n",
    "use_gamma = 1\n",
    "use_beta = 1\n",
    "use_coords = 1  # 0: none, 1: low usage, 2: high usage\n",
    "grad_clip = 0  # <= 0 for no grad clipping\n",
    "debug_every = float('inf') # inf for no pdb\n",
    "print_verbose_every = 200000  # inf for min print\n",
    "\n",
    "# # CNN options (for baselines)\n",
    "# cnn_res_block_dim = 128\n",
    "# cnn_num_res_blocks = 0\n",
    "# cnn_proj_dim = 512\n",
    "# cnn_pooling = 'maxpool2',\n",
    "# #   choices=['none', 'maxpool2'])\n",
    "\n",
    "# # Stacked-Attention options\n",
    "# stacked_attn_dim = 512\n",
    "# num_stacked_attn = 2\n",
    "\n",
    "# Classifier options\n",
    "classifier_proj_dim = 512\n",
    "classifier_downsample = 'maxpoolfull' \n",
    "#   choices=['maxpool2', 'maxpool3', 'maxpool4', 'maxpool5', 'maxpool7', 'maxpoolfull', 'none',\n",
    "#            'avgpool2', 'avgpool3', 'avgpool4', 'avgpool5', 'avgpool7', 'avgpoolfull', 'aggressive'])\n",
    "classifier_fc_dims = '1024'\n",
    "classifier_batchnorm = 1\n",
    "classifier_dropout = 0\n",
    "\n",
    "# Optimization options\n",
    "batch_size = 64\n",
    "num_iterations = 200000\n",
    "optimizer = 'Adam'\n",
    "#   choices=['Adadelta', 'Adagrad', 'Adam', 'Adamax', 'ASGD', 'RMSprop', 'SGD'])\n",
    "learning_rate = 3e-4\n",
    "reward_decay = 0.9\n",
    "weight_decay = 1e-5\n",
    "                    \n",
    "# Output options\n",
    "checkpoint_path = \"data/model/film.pt\"\n",
    "randomize_checkpoint_path = 0\n",
    "avoid_checkpoint_override = 0\n",
    "record_loss_every = 100\n",
    "checkpoint_every = 10000\n",
    "use_time = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b2a55",
   "metadata": {},
   "source": [
    "**===================================================== Main ===========================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4dfd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save checkpoints to data/model/film.pt\n"
     ]
    }
   ],
   "source": [
    "if randomize_checkpoint_path == 1:\n",
    "    name, ext = os.path.splitext(checkpoint_path)\n",
    "    num = random.randint(1, 1000000)\n",
    "    checkpoint_path = '%s_%06d%s' % (name, num, ext)\n",
    "print('Will save checkpoints to %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b74d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_local_copies == 1:\n",
    "    shutil.copy(train_question_h5, '/tmp/train_questions.h5')\n",
    "    shutil.copy(train_features_h5, '/tmp/train_features.h5')\n",
    "    shutil.copy(val_question_h5, '/tmp/val_questions.h5')\n",
    "    shutil.copy(val_features_h5, '/tmp/val_features.h5')\n",
    "    train_question_h5 = '/tmp/train_questions.h5'\n",
    "    train_features_h5 = '/tmp/train_features.h5'\n",
    "    val_question_h5 = '/tmp/val_questions.h5'\n",
    "    val_features_h5 = '/tmp/val_features.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6614280",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_families = None\n",
    "if family_split_file is not None:\n",
    "    with open(family_split_file, 'r') as f:\n",
    "        question_families = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc805f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = utils.load_vocab(vocab_json)\n",
    "\n",
    "train_loader_kwargs = {\n",
    "    'question_h5': train_questions_h5,\n",
    "    'feature_h5': train_features_h5,\n",
    "    'vocab': vocab,\n",
    "    'batch_size': batch_size,\n",
    "    'shuffle': shuffle_train_data == 1,\n",
    "#     'question_families': question_families,\n",
    "#     'max_samples': num_train_samples,\n",
    "#     'num_workers': loader_num_workers,\n",
    "}\n",
    "\n",
    "val_loader_kwargs = {\n",
    "    'question_h5': val_questions_h5,\n",
    "    'feature_h5': val_features_h5,\n",
    "    'vocab': vocab,\n",
    "    'batch_size': batch_size,\n",
    "#     'question_families': question_families,\n",
    "#     'max_samples': num_val_samples,\n",
    "#     'num_workers': loader_num_workers,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87000d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from data/train_features.h5\n",
      "Reading questions from  data/train_questions.h5\n",
      "Reading question data into memory\n",
      "Reading features from data/val_features.h5\n",
      "Reading questions from  data/val_questions.h5\n",
      "Reading question data into memory\n"
     ]
    }
   ],
   "source": [
    "train_loader = ClevrDataLoader(**train_loader_kwargs)\n",
    "val_loader = ClevrDataLoader(**val_loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65b15260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the conditioning network:\n",
      "FiLMGen(\n",
      "  (encoder_embed): Embedding(93, 200)\n",
      "  (encoder_rnn): GRU(200, 4096, batch_first=True)\n",
      "  (decoder_linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      ")\n",
      "Here is the conditioned network:\n",
      "FiLMedNet(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(1026, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (0): FiLMedResBlock(\n",
      "    (input_proj): Conv2d(130, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (film): FiLM()\n",
      "  )\n",
      "  (1): FiLMedResBlock(\n",
      "    (input_proj): Conv2d(130, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (film): FiLM()\n",
      "  )\n",
      "  (2): FiLMedResBlock(\n",
      "    (input_proj): Conv2d(130, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (film): FiLM()\n",
      "  )\n",
      "  (3): FiLMedResBlock(\n",
      "    (input_proj): Conv2d(130, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (film): FiLM()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Conv2d(130, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=14, stride=14, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Flatten()\n",
      "    (5): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Linear(in_features=1024, out_features=32, bias=True)\n",
      "  )\n",
      ")\n",
      "train_loader has 699989 samples\n",
      "val_loader has 149991 samples\n",
      "Starting epoch 1\n",
      "100 1.836553566455841\n",
      "200 1.15993994474411\n",
      "300 1.0895755207538604\n",
      "400 1.0681079989671707\n",
      "500 1.0387589263916015\n",
      "600 1.0592521333694458\n",
      "700 1.026228010058403\n",
      "800 1.0219819253683091\n",
      "900 1.0224533981084825\n",
      "1000 1.027229328751564\n",
      "1100 1.0245534569025039\n",
      "1200 1.0167552703619003\n",
      "1300 1.0107783472537994\n",
      "1400 1.0086876040697097\n",
      "1500 1.013145371079445\n",
      "1600 0.9999596202373504\n",
      "1700 1.0018121778964997\n",
      "1800 1.0023374158143996\n",
      "1900 0.9987112724781037\n",
      "2000 0.9811284124851227\n",
      "2100 0.9954233884811401\n",
      "2200 0.9767857354879379\n",
      "2300 0.9758337473869324\n",
      "2400 0.98480597615242\n",
      "2500 0.9989762800931931\n",
      "2600 0.9834338128566742\n",
      "2700 0.9841965961456299\n",
      "2800 0.973931193947792\n",
      "2900 0.9615131711959839\n",
      "3000 0.9614490693807602\n",
      "3100 0.9560927778482438\n",
      "3200 0.9634806805849075\n",
      "3300 0.9727478802204133\n",
      "3400 0.9410629069805145\n",
      "3500 0.9633917790651322\n",
      "3600 0.9613601726293564\n",
      "3700 0.9607096457481384\n",
      "3800 0.9420678573846817\n",
      "3900 0.9535846787691117\n",
      "4000 0.9424103552103043\n",
      "4100 0.9487265926599503\n",
      "4200 0.9579706764221192\n",
      "4300 0.9473842757940293\n",
      "4400 0.9465630596876144\n",
      "4500 0.9563226741552353\n",
      "4600 0.951896698474884\n",
      "4700 0.9530800700187683\n",
      "4800 0.9387699842453003\n",
      "4900 0.9259705901145935\n",
      "5000 0.940809749364853\n",
      "5100 0.9304956316947937\n",
      "5200 0.9339169472455978\n",
      "5300 0.9244396430253983\n",
      "5400 0.9277036052942276\n",
      "5500 0.9322125107049942\n",
      "5600 0.9413103359937668\n",
      "5700 0.9204514640569686\n",
      "5800 0.9324579101800918\n",
      "5900 0.9196496343612671\n",
      "6000 0.9273977750539779\n",
      "6100 0.931646044254303\n",
      "6200 0.9122327780723571\n",
      "6300 0.925307365655899\n",
      "6400 0.913549707531929\n",
      "6500 0.9292161673307419\n",
      "6600 0.9109105783700943\n",
      "6700 0.9081529223918915\n",
      "6800 0.9250340682268142\n",
      "6900 0.9053067487478256\n",
      "7000 0.9224873608350754\n",
      "7100 0.9184361332654953\n",
      "7200 0.9117082583904267\n",
      "7300 0.9185774618387222\n",
      "7400 0.9056345450878144\n",
      "7500 0.9081486403942108\n",
      "7600 0.9096300441026688\n",
      "7700 0.9128446435928345\n",
      "7800 0.8859878349304199\n",
      "7900 0.8972433191537857\n",
      "8000 0.9085563349723816\n",
      "8100 0.8981955689191818\n",
      "8200 0.9105357933044433\n",
      "8300 0.8987930232286453\n",
      "8400 0.897004519701004\n",
      "8500 0.9119169366359711\n",
      "8600 0.8964058327674865\n",
      "8700 0.8894510239362716\n",
      "8800 0.9011037427186966\n",
      "8900 0.8941473853588104\n",
      "9000 0.8939181089401245\n",
      "9100 0.9001964277029038\n",
      "9200 0.8931133919954299\n",
      "9300 0.9013070833683013\n",
      "9400 0.8918198281526566\n",
      "9500 0.8941699343919755\n",
      "9600 0.8904895049333572\n",
      "9700 0.8879953563213349\n",
      "9800 0.8936133307218551\n",
      "9900 0.881007741689682\n",
      "10000 0.8880970245599746\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.5263571885665529\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.5250915054903295\n",
      "Saving checkpoint to data/model/film.pt\n",
      "10100 0.8926637423038483\n",
      "10200 0.8855331331491471\n",
      "10300 0.8860969591140747\n",
      "10400 0.8807192802429199\n",
      "10500 0.8749747067689896\n",
      "10600 0.8701831114292145\n",
      "10700 0.896962331533432\n",
      "10800 0.8834686142206192\n",
      "10900 0.8859192472696304\n",
      "Starting epoch 2\n",
      "11000 0.8817149251699448\n",
      "11100 0.8747171580791473\n",
      "11200 0.885318706035614\n",
      "11300 0.8688758915662765\n",
      "11400 0.8764636611938477\n",
      "11500 0.8781880015134811\n",
      "11600 0.8828572463989258\n",
      "11700 0.8811779260635376\n",
      "11800 0.8743888187408447\n",
      "11900 0.887341742515564\n",
      "12000 0.8784742587804795\n",
      "12100 0.8694872349500656\n",
      "12200 0.864910129904747\n",
      "12300 0.8888952040672302\n",
      "12400 0.8669128441810607\n",
      "12500 0.8750623685121536\n",
      "12600 0.8707112938165664\n",
      "12700 0.8720340275764465\n",
      "12800 0.8894717842340469\n",
      "12900 0.878776090145111\n",
      "13000 0.8642755782604218\n",
      "13100 0.8816668182611466\n",
      "13200 0.8648337227106094\n",
      "13300 0.8767240536212921\n",
      "13400 0.869203479886055\n",
      "13500 0.8657659250497818\n",
      "13600 0.8712253141403198\n",
      "13700 0.8691963118314743\n",
      "13800 0.863360738158226\n",
      "13900 0.8538556110858917\n",
      "14000 0.8332648324966431\n",
      "14100 0.840518233180046\n",
      "14200 0.815451910495758\n",
      "14300 0.7873153173923493\n",
      "14400 0.7840105485916138\n",
      "14500 0.7647000533342362\n",
      "14600 0.756381943821907\n",
      "14700 0.7629956066608429\n",
      "14800 0.7497278684377671\n",
      "14900 0.7461431419849396\n",
      "15000 0.7531264358758927\n",
      "15100 0.7362812480330467\n",
      "15200 0.7494747114181518\n",
      "15300 0.7361418521404266\n",
      "15400 0.7348662316799164\n",
      "15500 0.7226223236322403\n",
      "15600 0.7283850568532944\n",
      "15700 0.7281626170873642\n",
      "15800 0.7204562169313431\n",
      "15900 0.7209092247486114\n",
      "16000 0.7060832232236862\n",
      "16100 0.7074613523483276\n",
      "16200 0.7041327011585236\n",
      "16300 0.703786523938179\n",
      "16400 0.7127909481525421\n",
      "16500 0.7015767347812653\n",
      "16600 0.7048778587579727\n",
      "16700 0.7072173810005188\n",
      "16800 0.6894494384527207\n",
      "16900 0.6819661092758179\n",
      "17000 0.6723149865865707\n",
      "17100 0.6533136087656021\n",
      "17200 0.6930479818582534\n",
      "17300 0.6843791300058365\n",
      "17400 0.66372029453516\n",
      "17500 0.6496481457352639\n",
      "17600 0.6737386852502822\n",
      "17700 0.6503838339447975\n",
      "17800 0.660054549574852\n",
      "17900 0.6451324906945228\n",
      "18000 0.633329365849495\n",
      "18100 0.640597462952137\n",
      "18200 0.6432605224847794\n",
      "18300 0.6219958877563476\n",
      "18400 0.618391500711441\n",
      "18500 0.6143655288219452\n",
      "18600 0.6229282921552658\n",
      "18700 0.6130390450358391\n",
      "18800 0.6098786425590516\n",
      "18900 0.6074358198046684\n",
      "19000 0.6101930138468742\n",
      "19100 0.6207005032896995\n",
      "19200 0.6055430042743682\n",
      "19300 0.6128172963857651\n",
      "19400 0.594179567694664\n",
      "19500 0.6117879089713096\n",
      "19600 0.6002313789725303\n",
      "19700 0.588441533446312\n",
      "19800 0.6034076872467995\n",
      "19900 0.6024118116497994\n",
      "20000 0.5920364454388618\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.7109974936006825\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.7018154422598689\n",
      "Saving checkpoint to data/model/film.pt\n",
      "20100 0.5943191376328468\n",
      "20200 0.5962096101045609\n",
      "20300 0.5815367516875267\n",
      "20400 0.5860016897320748\n",
      "20500 0.5838327878713607\n",
      "20600 0.5766643363237381\n",
      "20700 0.5818693262338638\n",
      "20800 0.5935130524635315\n",
      "20900 0.5944716003537178\n",
      "21000 0.5756727802753449\n",
      "21100 0.568967926800251\n",
      "21200 0.597776073217392\n",
      "21300 0.5870864608883858\n",
      "21400 0.577202427983284\n",
      "21500 0.5783238062262535\n",
      "21600 0.5764382535219192\n",
      "21700 0.5608449500799179\n",
      "21800 0.5783949080109596\n",
      "Starting epoch 3\n",
      "21900 0.5748629274964333\n",
      "22000 0.5553116029500962\n",
      "22100 0.5551923328638076\n",
      "22200 0.5624569770693779\n",
      "22300 0.5617996788024903\n",
      "22400 0.550768755376339\n",
      "22500 0.5493778491020203\n",
      "22600 0.5423946878314019\n",
      "22700 0.5472358873486519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22800 0.552116745710373\n",
      "22900 0.5573549512028694\n",
      "23000 0.5488115471601486\n",
      "23100 0.5519526559114456\n",
      "23200 0.5430575439333916\n",
      "23300 0.5500772643089294\n",
      "23400 0.5449420735239983\n",
      "23500 0.5522625967860222\n",
      "23600 0.5493263205885888\n",
      "23700 0.5344525122642517\n",
      "23800 0.5533543500304222\n",
      "23900 0.5450868389010429\n",
      "24000 0.5296371081471443\n",
      "24100 0.5251435461640358\n",
      "24200 0.5309477335214615\n",
      "24300 0.5392033058404923\n",
      "24400 0.5317319542169571\n",
      "24500 0.5337506759166718\n",
      "24600 0.5159598088264465\n",
      "24700 0.5428607159852982\n",
      "24800 0.5221349376440049\n",
      "24900 0.520672019124031\n",
      "25000 0.5201436048746109\n",
      "25100 0.5234619960188865\n",
      "25200 0.5180207926034928\n",
      "25300 0.524413021504879\n",
      "25400 0.5211636778712273\n",
      "25500 0.526202537715435\n",
      "25600 0.5233289936184883\n",
      "25700 0.5208331036567688\n",
      "25800 0.5246913641691208\n",
      "25900 0.5300843963027\n",
      "26000 0.5130077186226845\n",
      "26100 0.5270479610562324\n",
      "26200 0.517375156879425\n",
      "26300 0.5254812875390052\n",
      "26400 0.5124532839655876\n",
      "26500 0.5208446222543717\n",
      "26600 0.5377450212836266\n",
      "26700 0.49770855754613874\n",
      "26800 0.5082188174128532\n",
      "26900 0.5109210056066513\n",
      "27000 0.514688675403595\n",
      "27100 0.511307218670845\n",
      "27200 0.5250680392980576\n",
      "27300 0.5116510617733002\n",
      "27400 0.4999415448307991\n",
      "27500 0.4969584602117538\n",
      "27600 0.49612956285476684\n",
      "27700 0.49795163959264754\n",
      "27800 0.5118416041135788\n",
      "27900 0.49073058158159255\n",
      "28000 0.5102742427587509\n",
      "28100 0.5088307505846024\n",
      "28200 0.5003564497828483\n",
      "28300 0.4820446941256523\n",
      "28400 0.47103950440883635\n",
      "28500 0.514317738711834\n",
      "28600 0.4798442283272743\n",
      "28700 0.4991691449284554\n",
      "28800 0.49476431369781493\n",
      "28900 0.4845822414755821\n",
      "29000 0.48366476118564605\n",
      "29100 0.4958248937129974\n",
      "29200 0.5042905983328819\n",
      "29300 0.5015934312343597\n",
      "29400 0.4975726503133774\n",
      "29500 0.5150478559732438\n",
      "29600 0.4753666952252388\n",
      "29700 0.49179872542619707\n",
      "29800 0.4935394021868706\n",
      "29900 0.4964245653152466\n",
      "30000 0.49690185219049454\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.7786569432593856\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.7667060023601416\n",
      "Saving checkpoint to data/model/film.pt\n",
      "30100 0.4827130091190338\n",
      "30200 0.4748599162697792\n",
      "30300 0.4927945911884308\n",
      "30400 0.47953062325716017\n",
      "30500 0.49073423326015475\n",
      "30600 0.47891739338636397\n",
      "30700 0.47436330795288084\n",
      "30800 0.4764275076985359\n",
      "30900 0.48019263327121736\n",
      "31000 0.4650063607096672\n",
      "31100 0.4866569781303406\n",
      "31200 0.4934112924337387\n",
      "31300 0.4799887937307358\n",
      "31400 0.48938799411058426\n",
      "31500 0.4768648651242256\n",
      "31600 0.4772468852996826\n",
      "31700 0.4610026326775551\n",
      "31800 0.4784097221493721\n",
      "31900 0.46981720805168153\n",
      "32000 0.45391914397478106\n",
      "32100 0.47554332613945005\n",
      "32200 0.4635898765921593\n",
      "32300 0.46311156123876573\n",
      "32400 0.4564325660467148\n",
      "32500 0.4743357852101326\n",
      "32600 0.4667605337500572\n",
      "32700 0.4617271614074707\n",
      "32800 0.46177233099937437\n",
      "Starting epoch 4\n",
      "32900 0.43532453536987303\n",
      "33000 0.4468555170297623\n",
      "33100 0.4429388317465782\n",
      "33200 0.43026438444852827\n",
      "33300 0.4350558389723301\n",
      "33400 0.44988736987113953\n",
      "33500 0.4452897962927818\n",
      "33600 0.4354741221666336\n",
      "33700 0.44047518223524096\n",
      "33800 0.436597146987915\n",
      "33900 0.42751990258693695\n",
      "34000 0.44811159431934355\n",
      "34100 0.43579761356115343\n",
      "34200 0.4199873036146164\n",
      "34300 0.4299799358844757\n",
      "34400 0.43061827212572096\n",
      "34500 0.4520938411355019\n",
      "34600 0.4264803442358971\n",
      "34700 0.43242055863142015\n",
      "34800 0.43093745976686476\n",
      "34900 0.4037553432583809\n",
      "35000 0.40461427614092826\n",
      "35100 0.40283177345991134\n",
      "35200 0.4157277247309685\n",
      "35300 0.3977258004248142\n",
      "35400 0.3942148777842522\n",
      "35500 0.39491194754838943\n",
      "35600 0.4056690306961536\n",
      "35700 0.40693557128310204\n",
      "35800 0.3864638711512089\n",
      "35900 0.3735346284508705\n",
      "36000 0.401017534583807\n",
      "36100 0.3856493364274502\n",
      "36200 0.3828497062623501\n",
      "36300 0.38274362981319426\n",
      "36400 0.3741725942492485\n",
      "36500 0.38989634841680526\n",
      "36600 0.3758969965577126\n",
      "36700 0.38909275382757186\n",
      "36800 0.3763486497104168\n",
      "36900 0.3892958979308605\n",
      "37000 0.3783901137113571\n",
      "37100 0.3764832378923893\n",
      "37200 0.3940037779510021\n",
      "37300 0.3729167592525482\n",
      "37400 0.37680648133158684\n",
      "37500 0.38154947429895403\n",
      "37600 0.39525368586182597\n",
      "37700 0.3892416410148144\n",
      "37800 0.38463362872600554\n",
      "37900 0.4019145677983761\n",
      "38000 0.3833266046643257\n",
      "38100 0.3789300613105297\n",
      "38200 0.3793583497405052\n",
      "38300 0.37336736768484113\n",
      "38400 0.3754912140965462\n",
      "38500 0.3658693355321884\n",
      "38600 0.3842114447057247\n",
      "38700 0.38316259264945984\n",
      "38800 0.36684206828474997\n",
      "38900 0.3620952321588993\n",
      "39000 0.35915776833891866\n",
      "39100 0.3710305477678776\n",
      "39200 0.35856581702828405\n",
      "39300 0.36223055750131605\n",
      "39400 0.3930781626701355\n",
      "39500 0.3646761552989483\n",
      "39600 0.37166963905096057\n",
      "39700 0.3686398935317993\n",
      "39800 0.3759402486681938\n",
      "39900 0.36133748084306716\n",
      "40000 0.37090200915932653\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.8452165102389079\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.8297431179204086\n",
      "Saving checkpoint to data/model/film.pt\n",
      "40100 0.3605510407686234\n",
      "40200 0.36602467477321626\n",
      "40300 0.36026825904846194\n",
      "40400 0.3514224988222122\n",
      "40500 0.36691407203674314\n",
      "40600 0.3755813954770565\n",
      "40700 0.3675318743288517\n",
      "40800 0.3611013987660408\n",
      "40900 0.3649446088075638\n",
      "41000 0.35462325140833856\n",
      "41100 0.3751689204573631\n",
      "41200 0.36964447915554044\n",
      "41300 0.35813725233078003\n",
      "41400 0.3492096646130085\n",
      "41500 0.3624441124498844\n",
      "41600 0.3504141166806221\n",
      "41700 0.3651803994178772\n",
      "41800 0.3606864212453365\n",
      "41900 0.37608618184924125\n",
      "42000 0.35450438991189004\n",
      "42100 0.3442687477171421\n",
      "42200 0.3581660625338554\n",
      "42300 0.35928012371063234\n",
      "42400 0.36457001492381097\n",
      "42500 0.35469573497772217\n",
      "42600 0.34509716168045995\n",
      "42700 0.35809717178344724\n",
      "42800 0.3527669061720371\n",
      "42900 0.35153862670063973\n",
      "43000 0.34375857770442964\n",
      "43100 0.35666016295552255\n",
      "43200 0.3484015481173992\n",
      "43300 0.3546339356899261\n",
      "43400 0.3561955511569977\n",
      "43500 0.3535617297887802\n",
      "43600 0.34857956498861314\n",
      "43700 0.3515308356285095\n",
      "Starting epoch 5\n",
      "43800 0.3248706258833408\n",
      "43900 0.299906088411808\n",
      "44000 0.31116598322987554\n",
      "44100 0.3156768590211868\n",
      "44200 0.31567500948905947\n",
      "44300 0.3132695883512497\n",
      "44400 0.3208183127641678\n",
      "44500 0.31632145211100576\n",
      "44600 0.31249485939741134\n",
      "44700 0.3153734062612057\n",
      "44800 0.3046601052582264\n",
      "44900 0.31159445315599443\n",
      "45000 0.32094964385032654\n",
      "45100 0.32556746393442154\n",
      "45200 0.32801423758268355\n",
      "45300 0.3348847708106041\n",
      "45400 0.3316425667703152\n",
      "45500 0.3307406842708588\n",
      "45600 0.3228689841926098\n",
      "45700 0.324903571754694\n",
      "45800 0.32255538791418076\n",
      "45900 0.3378097701072693\n",
      "46000 0.3183526900410652\n",
      "46100 0.3134582826495171\n",
      "46200 0.3227388003468514\n",
      "46300 0.3198521380126476\n",
      "46400 0.3190618598461151\n",
      "46500 0.3145003552734852\n",
      "46600 0.31743712157011034\n",
      "46700 0.3260441145300865\n",
      "46800 0.31559551194310187\n",
      "46900 0.3096114020049572\n",
      "47000 0.31711813479661943\n",
      "47100 0.31983301863074304\n",
      "47200 0.3176720030605793\n",
      "47300 0.31277679473161696\n",
      "47400 0.3079216568171978\n",
      "47500 0.3079984848201275\n",
      "47600 0.3144317947328091\n",
      "47700 0.30104753002524376\n",
      "47800 0.30940109729766846\n",
      "47900 0.3316004078090191\n",
      "48000 0.3125994656980038\n",
      "48100 0.3042919112741947\n",
      "48200 0.30253421276807785\n",
      "48300 0.30805660352110864\n",
      "48400 0.3112057037651539\n",
      "48500 0.3093423508107662\n",
      "48600 0.30915869906544685\n",
      "48700 0.2881423817574978\n",
      "48800 0.30393423944711684\n",
      "48900 0.298820236325264\n",
      "49000 0.31301190599799156\n",
      "49100 0.31666949719190596\n",
      "49200 0.31703998491168023\n",
      "49300 0.3077597053349018\n",
      "49400 0.30198506072163583\n",
      "49500 0.29610748633742334\n",
      "49600 0.31474975392222404\n",
      "49700 0.3050213120877743\n",
      "49800 0.2880115158855915\n",
      "49900 0.30719770342111585\n",
      "50000 0.29924157112836836\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.8774397397610921\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.8618183757692128\n",
      "Saving checkpoint to data/model/film.pt\n",
      "50100 0.29333514243364334\n",
      "50200 0.3136623874306679\n",
      "50300 0.29899248883128166\n",
      "50400 0.2849091154336929\n",
      "50500 0.28662041917443276\n",
      "50600 0.29184952437877654\n",
      "50700 0.3148226417601109\n",
      "50800 0.2983889853954315\n",
      "50900 0.28981874153018\n",
      "51000 0.3080269818007946\n",
      "51100 0.29842335894703864\n",
      "51200 0.3080884198844433\n",
      "51300 0.29439112052321437\n",
      "51400 0.2987579675018787\n",
      "51500 0.29781899020075797\n",
      "51600 0.2913858099281788\n",
      "51700 0.27931336015462876\n",
      "51800 0.2897650860249996\n",
      "51900 0.28821501150727274\n",
      "52000 0.29829084932804106\n",
      "52100 0.27799461081624033\n",
      "52200 0.28377045020461084\n",
      "52300 0.29382199674844744\n",
      "52400 0.28570125699043275\n",
      "52500 0.29650386050343513\n",
      "52600 0.285511822104454\n",
      "52700 0.2923691947758198\n",
      "52800 0.28667622938752174\n",
      "52900 0.2752329054474831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53000 0.28969458423554895\n",
      "53100 0.28995426625013354\n",
      "53200 0.2847253792732954\n",
      "53300 0.2864800551533699\n",
      "53400 0.28114601120352745\n",
      "53500 0.2707497088611126\n",
      "53600 0.2729608348757029\n",
      "53700 0.2747162288427353\n",
      "53800 0.27027841441333295\n",
      "53900 0.2738074576854706\n",
      "54000 0.27603254973888397\n",
      "54100 0.28171239003539084\n",
      "54200 0.2768542796373367\n",
      "54300 0.29238562926650047\n",
      "54400 0.25619847513735294\n",
      "54500 0.28356209479272365\n",
      "54600 0.2651744943112135\n",
      "Starting epoch 6\n",
      "54700 0.27914311707019807\n",
      "54800 0.2527382605522871\n",
      "54900 0.24754643186926842\n",
      "55000 0.2462382982671261\n",
      "55100 0.26182757765054704\n",
      "55200 0.2519963289797306\n",
      "55300 0.2503359190374613\n",
      "55400 0.24650422513484954\n",
      "55500 0.25425347693264483\n",
      "55600 0.2405924255400896\n",
      "55700 0.2434904447942972\n",
      "55800 0.2368656425178051\n",
      "55900 0.25300650641322137\n",
      "56000 0.25605839766561983\n",
      "56100 0.2525894720107317\n",
      "56200 0.2515909046679735\n",
      "56300 0.2559241526946425\n",
      "56400 0.25064169213175774\n",
      "56500 0.23823778845369817\n",
      "56600 0.24265442676842214\n",
      "56700 0.25461901545524596\n",
      "56800 0.2633233845233917\n",
      "56900 0.23612790316343307\n",
      "57000 0.24154234290122986\n",
      "57100 0.24754806518554687\n",
      "57200 0.24467477828264236\n",
      "57300 0.2515097117424011\n",
      "57400 0.24647253699600696\n",
      "57500 0.24237024530768395\n",
      "57600 0.23346088483929633\n",
      "57700 0.22420806169509888\n",
      "57800 0.24128848388791085\n",
      "57900 0.23836079120635986\n",
      "58000 0.23927182145416737\n",
      "58100 0.24236977100372314\n",
      "58200 0.23823629409074784\n",
      "58300 0.24574135720729828\n",
      "58400 0.2504831576347351\n",
      "58500 0.2250258605927229\n",
      "58600 0.24073535516858102\n",
      "58700 0.24736335404217244\n",
      "58800 0.25152912065386773\n",
      "58900 0.24029699683189393\n",
      "59000 0.2520796349644661\n",
      "59100 0.22958272971212865\n",
      "59200 0.24703989058732986\n",
      "59300 0.2298883632570505\n",
      "59400 0.22545950464904307\n",
      "59500 0.24018215477466584\n",
      "59600 0.2375141789019108\n",
      "59700 0.24010195516049862\n",
      "59800 0.24079730577766895\n",
      "59900 0.22336655922234058\n",
      "60000 0.23387226209044457\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9072632252559727\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.8909201218739791\n",
      "Saving checkpoint to data/model/film.pt\n",
      "60100 0.22828340217471121\n",
      "60200 0.24235348373651505\n",
      "60300 0.23598985321819782\n",
      "60400 0.2355237977206707\n",
      "60500 0.21554078128188847\n",
      "60600 0.2268344461172819\n",
      "60700 0.23317044407129286\n",
      "60800 0.23724570512771606\n",
      "60900 0.22425556160509585\n",
      "61000 0.23243084102869033\n",
      "61100 0.23964942209422588\n",
      "61200 0.2386730717122555\n",
      "61300 0.24381103344261645\n",
      "61400 0.23515702590346335\n",
      "61500 0.2398549170047045\n",
      "61600 0.22302632600069047\n",
      "61700 0.23266409322619439\n",
      "61800 0.21895604752004147\n",
      "61900 0.2278915948420763\n",
      "62000 0.22756848916411399\n",
      "62100 0.23819698318839072\n",
      "62200 0.22546031042933465\n",
      "62300 0.22961957074701786\n",
      "62400 0.22444583930075168\n",
      "62500 0.206594258248806\n",
      "62600 0.23829804942011834\n",
      "62700 0.21761937215924262\n",
      "62800 0.21480404689908028\n",
      "62900 0.21669625774025916\n",
      "63000 0.22279317863285542\n",
      "63100 0.22775187641382216\n",
      "63200 0.22027503401041032\n",
      "63300 0.22936395913362503\n",
      "63400 0.22412125818431378\n",
      "63500 0.21914350993931295\n",
      "63600 0.2185090561211109\n",
      "63700 0.23147554539144038\n",
      "63800 0.24256437964737415\n",
      "63900 0.22617970660328865\n",
      "64000 0.24044664911925792\n",
      "64100 0.21143834926187993\n",
      "64200 0.23355098910629749\n",
      "64300 0.2273692862689495\n",
      "64400 0.22078974232077597\n",
      "64500 0.21562648124992848\n",
      "64600 0.2141805700212717\n",
      "64700 0.21850468948483467\n",
      "64800 0.22038709089159966\n",
      "64900 0.2281002762913704\n",
      "65000 0.23065465956926345\n",
      "65100 0.21982318870723247\n",
      "65200 0.214972984790802\n",
      "65300 0.22074155680835247\n",
      "65400 0.2231535167992115\n",
      "65500 0.21393186666071415\n",
      "65600 0.21150897741317748\n",
      "Starting epoch 7\n",
      "65700 0.20719755232334136\n",
      "65800 0.19674320351332425\n",
      "65900 0.2036765070259571\n",
      "66000 0.19011641435325147\n",
      "66100 0.19891312412917614\n",
      "66200 0.1906351487338543\n",
      "66300 0.20373507402837276\n",
      "66400 0.20096553936600686\n",
      "66500 0.19189707405865192\n",
      "66600 0.2017389304935932\n",
      "66700 0.200624927431345\n",
      "66800 0.2037917134910822\n",
      "66900 0.20539718829095363\n",
      "67000 0.19923828601837157\n",
      "67100 0.21405252777040004\n",
      "67200 0.21155530005693435\n",
      "67300 0.2068021109327674\n",
      "67400 0.20332246847450733\n",
      "67500 0.1926031443476677\n",
      "67600 0.1990673403441906\n",
      "67700 0.19889244861900807\n",
      "67800 0.19349994823336603\n",
      "67900 0.19278149135410785\n",
      "68000 0.2008362191915512\n",
      "68100 0.19819030538201332\n",
      "68200 0.20242262210696935\n",
      "68300 0.19529844358563422\n",
      "68400 0.19283404625952244\n",
      "68500 0.21764189846813678\n",
      "68600 0.19991610318422318\n",
      "68700 0.19339477367699145\n",
      "68800 0.1963267131894827\n",
      "68900 0.18918080627918243\n",
      "69000 0.19458104662597178\n",
      "69100 0.1980271352827549\n",
      "69200 0.21204223960638047\n",
      "69300 0.19921667724847794\n",
      "69400 0.20655718237161635\n",
      "69500 0.2026482931524515\n",
      "69600 0.1937523863464594\n",
      "69700 0.20547262154519558\n",
      "69800 0.20972197100520135\n",
      "69900 0.2044821934401989\n",
      "70000 0.20317539170384408\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9190019731228669\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9009340560433626\n",
      "Saving checkpoint to data/model/film.pt\n",
      "70100 0.20000276647508144\n",
      "70200 0.20514933444559574\n",
      "70300 0.19880772829055787\n",
      "70400 0.19355199448764324\n",
      "70500 0.1924563805013895\n",
      "70600 0.18395970445126295\n",
      "70700 0.19858277700841426\n",
      "70800 0.19800548173487187\n",
      "70900 0.20010842632502318\n",
      "71000 0.18646784000098704\n",
      "71100 0.20515389412641524\n",
      "71200 0.19436650417745113\n",
      "71300 0.20097154155373573\n",
      "71400 0.191172057390213\n",
      "71500 0.18734560377895831\n",
      "71600 0.19237397834658623\n",
      "71700 0.20209819369018078\n",
      "71800 0.2048618085682392\n",
      "71900 0.20116819187998772\n",
      "72000 0.20116012252867221\n",
      "72100 0.20854023322463036\n",
      "72200 0.19764737360179424\n",
      "72300 0.19747101850807666\n",
      "72400 0.1974754824489355\n",
      "72500 0.19733614832162857\n",
      "72600 0.19501679942011832\n",
      "72700 0.2015054479241371\n",
      "72800 0.1896196883916855\n",
      "72900 0.19137842133641242\n",
      "73000 0.19810379721224308\n",
      "73100 0.1998396435379982\n",
      "73200 0.18893071725964547\n",
      "73300 0.1992341934889555\n",
      "73400 0.19959414802491665\n",
      "73500 0.1954022327810526\n",
      "73600 0.18981956176459788\n",
      "73700 0.19079464361071585\n",
      "73800 0.19393676694482564\n",
      "73900 0.20209201864898205\n",
      "74000 0.1885647911578417\n",
      "74100 0.19187185510993005\n",
      "74200 0.19623904690146446\n",
      "74300 0.20583102874457837\n",
      "74400 0.19674869544804097\n",
      "74500 0.19192520663142204\n",
      "74600 0.19295965023338796\n",
      "74700 0.1912004841119051\n",
      "74800 0.19781171552836896\n",
      "74900 0.18879324018955232\n",
      "75000 0.19673580773174762\n",
      "75100 0.19295535050332546\n",
      "75200 0.20507712818682194\n",
      "75300 0.18902141690254212\n",
      "75400 0.1988323810696602\n",
      "75500 0.2085557184368372\n",
      "75600 0.1808419331163168\n",
      "75700 0.18603639230132102\n",
      "75800 0.1921867273002863\n",
      "75900 0.1934577713534236\n",
      "76000 0.2037077122926712\n",
      "76100 0.18711253829300403\n",
      "76200 0.18659844532608985\n",
      "76300 0.18458615742623807\n",
      "76400 0.1955890654027462\n",
      "76500 0.19244070827960968\n",
      "Starting epoch 8\n",
      "76600 0.17369797736406326\n",
      "76700 0.16554687276482583\n",
      "76800 0.16821042373776435\n",
      "76900 0.17263071440160274\n",
      "77000 0.16498394906520844\n",
      "77100 0.17469609797000885\n",
      "77200 0.1635275911167264\n",
      "77300 0.16642362136393785\n",
      "77400 0.17058712366968393\n",
      "77500 0.16010747529566288\n",
      "77600 0.16606807120144368\n",
      "77700 0.1614069515094161\n",
      "77800 0.16824026875197887\n",
      "77900 0.16389784440398217\n",
      "78000 0.18335781127214432\n",
      "78100 0.17054230555891992\n",
      "78200 0.1627957735955715\n",
      "78300 0.17657306689769028\n",
      "78400 0.18268570750951768\n",
      "78500 0.18062625229358673\n",
      "78600 0.1758524750173092\n",
      "78700 0.17990297004580497\n",
      "78800 0.167153887078166\n",
      "78900 0.16680250611156225\n",
      "79000 0.16307969396933913\n",
      "79100 0.16074078796431424\n",
      "79200 0.1676626382768154\n",
      "79300 0.17353243000805377\n",
      "79400 0.15455229304730891\n",
      "79500 0.16472108364105226\n",
      "79600 0.17408691726624967\n",
      "79700 0.16512033268809317\n",
      "79800 0.18030590381473302\n",
      "79900 0.17236831665039062\n",
      "80000 0.16994075894355773\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.933393771331058\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9178150689041342\n",
      "Saving checkpoint to data/model/film.pt\n",
      "80100 0.17313784390687942\n",
      "80200 0.1749979719519615\n",
      "80300 0.16908012472093106\n",
      "80400 0.16902995370328427\n",
      "80500 0.1771366712078452\n",
      "80600 0.16411784075200558\n",
      "80700 0.15048164959996937\n",
      "80800 0.16132566303014756\n",
      "80900 0.17166137531399728\n",
      "81000 0.1687046557292342\n",
      "81100 0.16293892331421375\n",
      "81200 0.17813361510634423\n",
      "81300 0.16601261302828788\n",
      "81400 0.16623617250472308\n",
      "81500 0.1676193868368864\n",
      "81600 0.1610035014152527\n",
      "81700 0.16189453717321156\n",
      "81800 0.16656627178192138\n",
      "81900 0.15776384335011243\n",
      "82000 0.166263125538826\n",
      "82100 0.16073538530617953\n",
      "82200 0.14824873697012664\n",
      "82300 0.15667992644011974\n",
      "82400 0.16067578203976154\n",
      "82500 0.15630619507282972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82600 0.153684634976089\n",
      "82700 0.16025638028979303\n",
      "82800 0.16444222539663314\n",
      "82900 0.15225987236946822\n",
      "83000 0.16000760614871978\n",
      "83100 0.1500969637557864\n",
      "83200 0.14823341179639102\n",
      "83300 0.16955406744033097\n",
      "83400 0.1543292959034443\n",
      "83500 0.15809020724147557\n",
      "83600 0.15433481387794018\n",
      "83700 0.15983066141605376\n",
      "83800 0.14704279858618974\n",
      "83900 0.15851377550512552\n",
      "84000 0.15094286814332009\n",
      "84100 0.14656122032552957\n",
      "84200 0.1558094662427902\n",
      "84300 0.15036870718002318\n",
      "84400 0.15047773994505406\n",
      "84500 0.15665729727596045\n",
      "84600 0.16055653732270003\n",
      "84700 0.14998469691723584\n",
      "84800 0.15496938899159432\n",
      "84900 0.15282773364335298\n",
      "85000 0.16728490009903907\n",
      "85100 0.15492873903363943\n",
      "85200 0.1548011301085353\n",
      "85300 0.15220348227769137\n",
      "85400 0.14572662308812143\n",
      "85500 0.15560006212443114\n",
      "85600 0.14933821268379688\n",
      "85700 0.14846060950309037\n",
      "85800 0.15316759750247003\n",
      "85900 0.16007165279239416\n",
      "86000 0.15756123494356872\n",
      "86100 0.14680694796144964\n",
      "86200 0.15090334050357343\n",
      "86300 0.14709012843668462\n",
      "86400 0.15973003413528203\n",
      "86500 0.15925789963454007\n",
      "86600 0.15472392350435257\n",
      "86700 0.14980208210647106\n",
      "86800 0.1483133491128683\n",
      "86900 0.14792025443166495\n",
      "87000 0.16159498531371355\n",
      "87100 0.15463216915726663\n",
      "87200 0.15317235112190247\n",
      "87300 0.1517193891108036\n",
      "87400 0.13878802537918092\n",
      "87500 0.1580561038479209\n",
      "Starting epoch 9\n",
      "87600 0.13258968316018582\n",
      "87700 0.12899169912561775\n",
      "87800 0.1287946715205908\n",
      "87900 0.1278860217705369\n",
      "88000 0.1345898255519569\n",
      "88100 0.12633478943258525\n",
      "88200 0.13200294218957423\n",
      "88300 0.12935898959636688\n",
      "88400 0.14052927538752555\n",
      "88500 0.13852340273559094\n",
      "88600 0.13251933436840774\n",
      "88700 0.13019805945456028\n",
      "88800 0.12744917456060648\n",
      "88900 0.14251231882721185\n",
      "89000 0.13678387250751256\n",
      "89100 0.1333738673105836\n",
      "89200 0.13668456062674522\n",
      "89300 0.13660018851980568\n",
      "89400 0.13615295020863413\n",
      "89500 0.1332200864702463\n",
      "89600 0.14105714295059443\n",
      "89700 0.13418620213866234\n",
      "89800 0.13629899319261313\n",
      "89900 0.1374432499706745\n",
      "90000 0.13490144794806838\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9479855482081911\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9331893246928149\n",
      "Saving checkpoint to data/model/film.pt\n",
      "90100 0.13187885206192732\n",
      "90200 0.13594726849347352\n",
      "90300 0.13306884936988353\n",
      "90400 0.1320199516415596\n",
      "90500 0.13234586216509342\n",
      "90600 0.13005108566954732\n",
      "90700 0.13325916588306427\n",
      "90800 0.13629974126815797\n",
      "90900 0.13089841656386852\n",
      "91000 0.13568714562803508\n",
      "91100 0.1388207211345434\n",
      "91200 0.12765779584646225\n",
      "91300 0.1399656480550766\n",
      "91400 0.1327583720162511\n",
      "91500 0.13795393612235785\n",
      "91600 0.13814809022471308\n",
      "91700 0.1363002124801278\n",
      "91800 0.14163471404463052\n",
      "91900 0.13312415566295385\n",
      "92000 0.13028263295069337\n",
      "92100 0.14597905933856964\n",
      "92200 0.14662533149123191\n",
      "92300 0.13792121363803744\n",
      "92400 0.1424031289294362\n",
      "92500 0.13240750946104526\n",
      "92600 0.14154636532068252\n",
      "92700 0.1344563630223274\n",
      "92800 0.13951444141566754\n",
      "92900 0.1312637310102582\n",
      "93000 0.13383242793381214\n",
      "93100 0.15113063534721732\n",
      "93200 0.1297826511785388\n",
      "93300 0.1428775829076767\n",
      "93400 0.12772883599624038\n",
      "93500 0.1287010377086699\n",
      "93600 0.12986333766952157\n",
      "93700 0.12950609494000673\n",
      "93800 0.1342189598083496\n",
      "93900 0.1329609026387334\n",
      "94000 0.13874789983034133\n",
      "94100 0.13062866892665626\n",
      "94200 0.1403330601984635\n",
      "94300 0.1291165218874812\n",
      "94400 0.13469882365316152\n",
      "94500 0.13285513134673238\n",
      "94600 0.13409648809581995\n",
      "94700 0.13579114381223917\n",
      "94800 0.13979450311511754\n",
      "94900 0.13335232835263014\n",
      "95000 0.13578699449077247\n",
      "95100 0.13059169506654145\n",
      "95200 0.134950776360929\n",
      "95300 0.12246020115911961\n",
      "95400 0.1426678332313895\n",
      "95500 0.130851132273674\n",
      "95600 0.1421763514354825\n",
      "95700 0.1275782959163189\n",
      "95800 0.1371870185062289\n",
      "95900 0.12527327939867974\n",
      "96000 0.13118939861655235\n",
      "96100 0.1382008995488286\n",
      "96200 0.12932668048888446\n",
      "96300 0.12781618850305676\n",
      "96400 0.12854296484962105\n",
      "96500 0.14084362249821425\n",
      "96600 0.12680244255810977\n",
      "96700 0.136181844137609\n",
      "96800 0.1283570360764861\n",
      "96900 0.1338389760442078\n",
      "97000 0.1367849987000227\n",
      "97100 0.14149282798171042\n",
      "97200 0.13674211675301196\n",
      "97300 0.12816898008808494\n",
      "97400 0.1347866152599454\n",
      "97500 0.1366009022295475\n",
      "97600 0.1346821434609592\n",
      "97700 0.1324762472882867\n",
      "97800 0.13060247886925935\n",
      "97900 0.1342633157595992\n",
      "98000 0.13346092741936444\n",
      "98100 0.12138497216627002\n",
      "98200 0.12387880905531347\n",
      "98300 0.11906201239675283\n",
      "98400 0.11848573327064514\n",
      "Starting epoch 10\n",
      "98500 0.13204888644628227\n",
      "98600 0.10753283461555839\n",
      "98700 0.11416297908872367\n",
      "98800 0.1095212531927973\n",
      "98900 0.10757547110319138\n",
      "99000 0.12038898035883903\n",
      "99100 0.11548188127577305\n",
      "99200 0.12216790083795787\n",
      "99300 0.1048434635438025\n",
      "99400 0.11521687250584364\n",
      "99500 0.11109053310006857\n",
      "99600 0.11140681624412536\n",
      "99700 0.10894034497439861\n",
      "99800 0.12498992640525103\n",
      "99900 0.11511450860649347\n",
      "100000 0.11680119749158621\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9557647184300341\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9402764165849951\n",
      "Saving checkpoint to data/model/film.pt\n",
      "100100 0.11346769873052835\n",
      "100200 0.11798987913876773\n",
      "100300 0.124361063092947\n",
      "100400 0.1329901271313429\n",
      "100500 0.12284621514379979\n",
      "100600 0.1222027238830924\n",
      "100700 0.12222925908863544\n",
      "100800 0.12177852423861622\n",
      "100900 0.114339100420475\n",
      "101000 0.11351559210568667\n",
      "101100 0.11805020282045006\n",
      "101200 0.12682237992063164\n",
      "101300 0.12095219153910876\n",
      "101400 0.10925451535731553\n",
      "101500 0.1135969508253038\n",
      "101600 0.11555251924321056\n",
      "101700 0.12177172707393766\n",
      "101800 0.12441619995981455\n",
      "101900 0.11538887599483133\n",
      "102000 0.12583272952586413\n",
      "102100 0.1258858124911785\n",
      "102200 0.11864398911595345\n",
      "102300 0.11063253870233894\n",
      "102400 0.1268901004269719\n",
      "102500 0.12002874549478293\n",
      "102600 0.11784150892868638\n",
      "102700 0.1114440126903355\n",
      "102800 0.11353763297200203\n",
      "102900 0.11595002854242921\n",
      "103000 0.12668997582048178\n",
      "103100 0.11948985474184155\n",
      "103200 0.11497525330632925\n",
      "103300 0.11287311930209398\n",
      "103400 0.11249741677194834\n",
      "103500 0.11332355789840222\n",
      "103600 0.11201270086690783\n",
      "103700 0.12215552985668182\n",
      "103800 0.11997403249144555\n",
      "103900 0.1198205174319446\n",
      "104000 0.13093689443543555\n",
      "104100 0.11406300932168961\n",
      "104200 0.11627422213554382\n",
      "104300 0.12347577095031738\n",
      "104400 0.11813571918755769\n",
      "104500 0.1264493338391185\n",
      "104600 0.12115364821627736\n",
      "104700 0.1247615797445178\n",
      "104800 0.1205448691919446\n",
      "104900 0.1196103117801249\n",
      "105000 0.12290499281138181\n",
      "105100 0.11989564202725887\n",
      "105200 0.1135890961997211\n",
      "105300 0.1270047341659665\n",
      "105400 0.11784648375585675\n",
      "105500 0.11852890454232692\n",
      "105600 0.11329962577670813\n",
      "105700 0.12365173105150461\n",
      "105800 0.11296774474903941\n",
      "105900 0.12162675628438592\n",
      "106000 0.13110305910930037\n",
      "106100 0.12269821461290122\n",
      "106200 0.11897630799561738\n",
      "106300 0.11965566026046873\n",
      "106400 0.13502104792743921\n",
      "106500 0.12037084704264998\n",
      "106600 0.12707954231649637\n",
      "106700 0.13020900513976813\n",
      "106800 0.1233734137378633\n",
      "106900 0.12710623426362871\n",
      "107000 0.12049106540158391\n",
      "107100 0.11610189501196146\n",
      "107200 0.11952812943607569\n",
      "107300 0.13083328494802118\n",
      "107400 0.10473770381882787\n",
      "107500 0.1340554154664278\n",
      "107600 0.11947272878140211\n",
      "107700 0.12099093567579984\n",
      "107800 0.11451643459498882\n",
      "107900 0.12756058951839805\n",
      "108000 0.1324886080995202\n",
      "108100 0.1134077006392181\n",
      "108200 0.1163300846889615\n",
      "108300 0.10954368865117431\n",
      "108400 0.11632466707378626\n",
      "108500 0.11898182583972812\n",
      "108600 0.1218980660289526\n",
      "108700 0.1164361534267664\n",
      "108800 0.12712561387568713\n",
      "108900 0.11933289464563131\n",
      "109000 0.12550343858078122\n",
      "109100 0.12208462666720152\n",
      "109200 0.11852182427421212\n",
      "109300 0.12044862762093544\n",
      "Starting epoch 11\n",
      "109400 0.12391572631895542\n",
      "109500 0.10393396899104118\n",
      "109600 0.10582310065627099\n",
      "109700 0.10452225478366017\n",
      "109800 0.10658038722351193\n",
      "109900 0.10888520343229174\n",
      "110000 0.10595117473974824\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9557380546075085\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9409497903207525\n",
      "Saving checkpoint to data/model/film.pt\n",
      "110100 0.1133865162730217\n",
      "110200 0.1093641059845686\n",
      "110300 0.10780728299170733\n",
      "110400 0.11463251074776054\n",
      "110500 0.11149028313346207\n",
      "110600 0.10122226502746344\n",
      "110700 0.10686279578134418\n",
      "110800 0.10003711801022291\n",
      "110900 0.10372849097475409\n",
      "111000 0.09661755150184036\n",
      "111100 0.10971010172739624\n",
      "111200 0.11392943766899406\n",
      "111300 0.11090441137552261\n",
      "111400 0.10835587188601493\n",
      "111500 0.10358190687373281\n",
      "111600 0.0994491670653224\n",
      "111700 0.10825987247750163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111800 0.10040850376710296\n",
      "111900 0.10219437347725034\n",
      "112000 0.10842554215341807\n",
      "112100 0.11597565904259682\n",
      "112200 0.10486890234053135\n",
      "112300 0.11003089383244515\n",
      "112400 0.10883963594213128\n",
      "112500 0.1032823439128697\n",
      "112600 0.10701737768948077\n",
      "112700 0.11653759044595063\n",
      "112800 0.10818424448370934\n",
      "112900 0.11385965446010232\n",
      "113000 0.11124090250581503\n",
      "113100 0.10659208636730909\n",
      "113200 0.11684056214988231\n",
      "113300 0.10493999257683755\n",
      "113400 0.11163796406239271\n",
      "113500 0.09634897517040372\n",
      "113600 0.10453335143625736\n",
      "113700 0.1049524282477796\n",
      "113800 0.1112387222982943\n",
      "113900 0.11473503399640322\n",
      "114000 0.11159099880605935\n",
      "114100 0.10579619653522969\n",
      "114200 0.1154406563937664\n",
      "114300 0.11358968760818243\n",
      "114400 0.10483675722032786\n",
      "114500 0.12333631608635187\n",
      "114600 0.11408290769904852\n",
      "114700 0.10767993049696088\n",
      "114800 0.10612019559368491\n",
      "114900 0.10052322445437312\n",
      "115000 0.10724138397723436\n",
      "115100 0.11261343352496624\n",
      "115200 0.10304467437788845\n",
      "115300 0.11912995483726263\n",
      "115400 0.11435886960476636\n",
      "115500 0.10838669847697019\n",
      "115600 0.12042267991695553\n",
      "115700 0.1188589478097856\n",
      "115800 0.11054340451955795\n",
      "115900 0.10520348044112325\n",
      "116000 0.10901474410668016\n",
      "116100 0.11805788518860937\n",
      "116200 0.10748688451945781\n",
      "116300 0.09937437932938337\n",
      "116400 0.1066120334342122\n",
      "116500 0.11431155737489462\n",
      "116600 0.1152075390331447\n",
      "116700 0.10806837840005755\n",
      "116800 0.11296821295283735\n",
      "116900 0.1100911771133542\n",
      "117000 0.1048270126618445\n",
      "117100 0.11471626605838538\n",
      "117200 0.1180477211251855\n",
      "117300 0.12151772028766572\n",
      "117400 0.1155694368109107\n",
      "117500 0.12263862246647478\n",
      "117600 0.1099926002137363\n",
      "117700 0.11198195787146688\n",
      "117800 0.10674878056161105\n",
      "117900 0.1161850829795003\n",
      "118000 0.11264742016792298\n",
      "118100 0.11118134498596191\n",
      "118200 0.11344289381057024\n",
      "118300 0.1102806468680501\n",
      "118400 0.11164041523821652\n",
      "118500 0.10100098475813865\n",
      "118600 0.10655514376237989\n",
      "118700 0.10197860579937697\n",
      "118800 0.10910305228084326\n",
      "118900 0.1072719513438642\n",
      "119000 0.1243482680246234\n",
      "119100 0.11394181737676262\n",
      "119200 0.10967237444594502\n",
      "119300 0.1067587580345571\n",
      "119400 0.10640854617580771\n",
      "119500 0.10743468482978642\n",
      "119600 0.11073408402502537\n",
      "119700 0.11339716337621213\n",
      "119800 0.1073353591002524\n",
      "119900 0.11103732109069825\n",
      "120000 0.10383586686104536\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9639505119453925\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9487835936822876\n",
      "Saving checkpoint to data/model/film.pt\n",
      "120100 0.11031202845275402\n",
      "120200 0.11926739377900958\n",
      "120300 0.1162282226420939\n",
      "Starting epoch 12\n",
      "120400 0.0970882497727871\n",
      "120500 0.09686851069331169\n",
      "120600 0.10050588391721249\n",
      "120700 0.0872490631043911\n",
      "120800 0.08931315859779715\n",
      "120900 0.08836962745524943\n",
      "121000 0.09290807886049152\n",
      "121100 0.08998601061291993\n",
      "121200 0.09177800366654992\n",
      "121300 0.09269702862948179\n",
      "121400 0.09149747882038355\n",
      "121500 0.09872957811690868\n",
      "121600 0.1075051412312314\n",
      "121700 0.10431024145334959\n",
      "121800 0.1062010894715786\n",
      "121900 0.1114226098358631\n",
      "122000 0.1016344966366887\n",
      "122100 0.09715854527428747\n",
      "122200 0.09867319934070111\n",
      "122300 0.10152009090408683\n",
      "122400 0.10731440551578998\n",
      "122500 0.10561772118322552\n",
      "122600 0.09695617885328829\n",
      "122700 0.10851523069664835\n",
      "122800 0.1074670479632914\n",
      "122900 0.10201154755428433\n",
      "123000 0.10714598592370748\n",
      "123100 0.09805058592930437\n",
      "123200 0.09739256013184786\n",
      "123300 0.10150710068643093\n",
      "123400 0.09111914230510593\n",
      "123500 0.10033247672021389\n",
      "123600 0.09768687145784498\n",
      "123700 0.09536787923425435\n",
      "123800 0.11124068999662995\n",
      "123900 0.10618009939789771\n",
      "124000 0.102183837890625\n",
      "124100 0.11039884306490422\n",
      "124200 0.08779294279403985\n",
      "124300 0.10152103634551167\n",
      "124400 0.10858485342934728\n",
      "124500 0.11390303488820791\n",
      "124600 0.11028753623366355\n",
      "124700 0.10601372379809618\n",
      "124800 0.10243133321404457\n",
      "124900 0.1006304682046175\n",
      "125000 0.11462244931608438\n",
      "125100 0.11103403126820922\n",
      "125200 0.0996231722831726\n",
      "125300 0.09489916730672121\n",
      "125400 0.10551324348896741\n",
      "125500 0.09907162502408028\n",
      "125600 0.1040264581888914\n",
      "125700 0.0996027459576726\n",
      "125800 0.09914774175733328\n",
      "125900 0.11394181322306395\n",
      "126000 0.10939322687685489\n",
      "126100 0.09807397982105613\n",
      "126200 0.11060054609552025\n",
      "126300 0.10223438186571002\n",
      "126400 0.10015387224033474\n",
      "126500 0.1058409714512527\n",
      "126600 0.1123586817085743\n",
      "126700 0.10934285899624228\n",
      "126800 0.09946290016174317\n",
      "126900 0.10453418990597128\n",
      "127000 0.1022551872767508\n",
      "127100 0.10504701325669885\n",
      "127200 0.10604918190278113\n",
      "127300 0.09763784106820822\n",
      "127400 0.1009452049806714\n",
      "127500 0.09572465857490897\n",
      "127600 0.10325074503198266\n",
      "127700 0.10523199386894704\n",
      "127800 0.11263286776840686\n",
      "127900 0.10871148882433772\n",
      "128000 0.11527436550706625\n",
      "128100 0.10194158151745797\n",
      "128200 0.10499838573858142\n",
      "128300 0.10619968179613352\n",
      "128400 0.10393947888165712\n",
      "128500 0.10771110972389579\n",
      "128600 0.11058013925328851\n",
      "128700 0.09779716324061155\n",
      "128800 0.10451780300121755\n",
      "128900 0.10776982814073563\n",
      "129000 0.10184205889701843\n",
      "129100 0.1100173912383616\n",
      "129200 0.10162100207060576\n",
      "129300 0.10769663436338306\n",
      "129400 0.11008330427110195\n",
      "129500 0.09636590115725994\n",
      "129600 0.09492666634730995\n",
      "129700 0.09770775133743882\n",
      "129800 0.10953227922320366\n",
      "129900 0.1101754704490304\n",
      "130000 0.10280731808394193\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9618440699658704\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9466901347414178\n",
      "Saving checkpoint to data/model/film.pt\n",
      "130100 0.09952630741521716\n",
      "130200 0.10452390091493725\n",
      "130300 0.10619897169992328\n",
      "130400 0.09984678369015455\n",
      "130500 0.09987136961892247\n",
      "130600 0.10712405484169722\n",
      "130700 0.10667943309992552\n",
      "130800 0.10384107548743486\n",
      "130900 0.1037886968255043\n",
      "131000 0.10597145166248083\n",
      "131100 0.10884617026895285\n",
      "131200 0.09999099360778928\n",
      "Starting epoch 13\n",
      "131300 0.09191668057814241\n",
      "131400 0.10088931758888066\n",
      "131500 0.08892631318420172\n",
      "131600 0.08941477101296186\n",
      "131700 0.0957224834896624\n",
      "131800 0.09001009115949272\n",
      "131900 0.09094778524711727\n",
      "132000 0.09521621876396238\n",
      "132100 0.09782930687069893\n",
      "132200 0.10276875620707869\n",
      "132300 0.0978408844769001\n",
      "132400 0.10055011805146932\n",
      "132500 0.09919196738861501\n",
      "132600 0.09039849773049355\n",
      "132700 0.09646617873571812\n",
      "132800 0.09066292114555835\n",
      "132900 0.09186161764431745\n",
      "133000 0.09389789812266827\n",
      "133100 0.08821328333579004\n",
      "133200 0.09922608849592507\n",
      "133300 0.08744623515754939\n",
      "133400 0.08717242838814855\n",
      "133500 0.09243221698328853\n",
      "133600 0.09565660361200572\n",
      "133700 0.1042179474234581\n",
      "133800 0.10330059988424183\n",
      "133900 0.1022930796816945\n",
      "134000 0.09986012834124267\n",
      "134100 0.0945981190726161\n",
      "134200 0.09572013687342405\n",
      "134300 0.10020044575445354\n",
      "134400 0.10788875931873917\n",
      "134500 0.09421404812484979\n",
      "134600 0.08315393628552556\n",
      "134700 0.08662785481661558\n",
      "134800 0.09079488383606077\n",
      "134900 0.09012232134118676\n",
      "135000 0.1043705957941711\n",
      "135100 0.10687304121442139\n",
      "135200 0.10955158337950706\n",
      "135300 0.09368905553594231\n",
      "135400 0.09386597903445364\n",
      "135500 0.09447162030264736\n",
      "135600 0.08706861565820873\n",
      "135700 0.08711241502314807\n",
      "135800 0.09009277096018195\n",
      "135900 0.10354130750522017\n",
      "136000 0.10387535709887744\n",
      "136100 0.09463043277151882\n",
      "136200 0.0962607491761446\n",
      "136300 0.09658301301300526\n",
      "136400 0.09518065608106553\n",
      "136500 0.09511791126802564\n",
      "136600 0.10325676249340177\n",
      "136700 0.10764546429738403\n",
      "136800 0.10478656342253088\n",
      "136900 0.09848548725247383\n",
      "137000 0.0976638695038855\n",
      "137100 0.09325404718518257\n",
      "137200 0.09525273753330112\n",
      "137300 0.09339336417615414\n",
      "137400 0.10130384001880884\n",
      "137500 0.09116377675905823\n",
      "137600 0.10184425167739392\n",
      "137700 0.1062558439746499\n",
      "137800 0.10346720717847348\n",
      "137900 0.11013972833752632\n",
      "138000 0.10702629305422307\n",
      "138100 0.09833852550014853\n",
      "138200 0.10333086444064975\n",
      "138300 0.11019608117640019\n",
      "138400 0.09849815787747503\n",
      "138500 0.0982907128892839\n",
      "138600 0.10472829880192876\n",
      "138700 0.09953140558674932\n",
      "138800 0.09926059616729617\n",
      "138900 0.10396749939769506\n",
      "139000 0.09839213410392404\n",
      "139100 0.09260234982706607\n",
      "139200 0.09480288935825229\n",
      "139300 0.09451525998301805\n",
      "139400 0.11360805246978999\n",
      "139500 0.09948239688761533\n",
      "139600 0.10423289412632585\n",
      "139700 0.10779805614612997\n",
      "139800 0.10356389595195652\n",
      "139900 0.10082637069746853\n",
      "140000 0.09962614415213465\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9646237734641638\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9491636164836557\n",
      "Saving checkpoint to data/model/film.pt\n",
      "140100 0.09650456309318542\n",
      "140200 0.10013383133336902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140300 0.10488581199198961\n",
      "140400 0.09492070930078626\n",
      "140500 0.10799072735011578\n",
      "140600 0.10015062627382576\n",
      "140700 0.09166053951717913\n",
      "140800 0.09395239420235157\n",
      "140900 0.09638002017512917\n",
      "141000 0.10185590889304877\n",
      "141100 0.09182635179720819\n",
      "141200 0.1001088048145175\n",
      "141300 0.10531288497149945\n",
      "141400 0.10530803771689534\n",
      "141500 0.0993230776488781\n",
      "141600 0.11118155579082668\n",
      "141700 0.09685064770281315\n",
      "141800 0.09909408615902066\n",
      "141900 0.09214184932410717\n",
      "142000 0.09994968932121992\n",
      "142100 0.09412479177117347\n",
      "Starting epoch 14\n",
      "142200 0.08541133278049529\n",
      "142300 0.09042258964851499\n",
      "142400 0.08266820192337036\n",
      "142500 0.09011345200240611\n",
      "142600 0.08302684711292387\n",
      "142700 0.08570863251574337\n",
      "142800 0.08293975952081382\n",
      "142900 0.09039875300601125\n",
      "143000 0.09289288597181439\n",
      "143100 0.0862733101285994\n",
      "143200 0.08745196521282196\n",
      "143300 0.0959821783285588\n",
      "143400 0.09296730762347578\n",
      "143500 0.09266368087381124\n",
      "143600 0.0889063161239028\n",
      "143700 0.091357637103647\n",
      "143800 0.096501869186759\n",
      "143900 0.09662917662411928\n",
      "144000 0.09299302847124637\n",
      "144100 0.08343486996367573\n",
      "144200 0.09135385194793344\n",
      "144300 0.08965275572612881\n",
      "144400 0.08910829391330481\n",
      "144500 0.09360472455620766\n",
      "144600 0.09021833524107933\n",
      "144700 0.09454422568902374\n",
      "144800 0.08910380557179451\n",
      "144900 0.09455888688564301\n",
      "145000 0.0858260946907103\n",
      "145100 0.08929471800336614\n",
      "145200 0.07987132135778666\n",
      "145300 0.09084127782844006\n",
      "145400 0.10594351896084846\n",
      "145500 0.0936587006598711\n",
      "145600 0.09102402541786432\n",
      "145700 0.08133149031549693\n",
      "145800 0.08857872165739536\n",
      "145900 0.09595214053988457\n",
      "146000 0.09502071788534522\n",
      "146100 0.09624072968959808\n",
      "146200 0.09017541174776852\n",
      "146300 0.09229132184758783\n",
      "146400 0.09597882742062211\n",
      "146500 0.09496482145041227\n",
      "146600 0.08913338055834175\n",
      "146700 0.09284336186014115\n",
      "146800 0.09839000208303332\n",
      "146900 0.08548452451825142\n",
      "147000 0.0860771054867655\n",
      "147100 0.0966818927321583\n",
      "147200 0.09770433517172933\n",
      "147300 0.09587460486218333\n",
      "147400 0.08766523037105799\n",
      "147500 0.08805801924318075\n",
      "147600 0.09067039273679256\n",
      "147700 0.10774329936131835\n",
      "147800 0.09626700805500149\n",
      "147900 0.08938190812245012\n",
      "148000 0.08862160066142678\n",
      "148100 0.09483033612370491\n",
      "148200 0.09434432867914438\n",
      "148300 0.09394612979143858\n",
      "148400 0.08648423062637449\n",
      "148500 0.08651969177648425\n",
      "148600 0.07675371116027235\n",
      "148700 0.09342170298099518\n",
      "148800 0.09893641578964889\n",
      "148900 0.09212341556325555\n",
      "149000 0.09682395178824663\n",
      "149100 0.09373106081504375\n",
      "149200 0.1040964338183403\n",
      "149300 0.09518092079088092\n",
      "149400 0.09840084921568631\n",
      "149500 0.09188094122335315\n",
      "149600 0.08922547060530633\n",
      "149700 0.0957028238195926\n",
      "149800 0.08804691633209587\n",
      "149900 0.10104322541505098\n",
      "150000 0.10235344016924501\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9540848976109215\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9397230500496696\n",
      "Saving checkpoint to data/model/film.pt\n",
      "150100 0.11130451869219542\n",
      "150200 0.0951191702671349\n",
      "150300 0.10213383268564939\n",
      "150400 0.09677305782213808\n",
      "150500 0.08909701797179878\n",
      "150600 0.09545140978880226\n",
      "150700 0.09242237824946642\n",
      "150800 0.09499951761215925\n",
      "150900 0.10039052568376064\n",
      "151000 0.09453969525173306\n",
      "151100 0.09477361978031695\n",
      "151200 0.09437519932165742\n",
      "151300 0.09094747435301542\n",
      "151400 0.08882106142584234\n",
      "151500 0.1025612439122051\n",
      "151600 0.09341730112209916\n",
      "151700 0.08678610125556588\n",
      "151800 0.08786720585078\n",
      "151900 0.09306643944233656\n",
      "152000 0.09073410946875811\n",
      "152100 0.10005269039422274\n",
      "152200 0.1000433356128633\n",
      "152300 0.10302011277526617\n",
      "152400 0.10023990803398192\n",
      "152500 0.09373218939639628\n",
      "152600 0.09087275332771241\n",
      "152700 0.09952742086723447\n",
      "152800 0.1009005508478731\n",
      "152900 0.09478428237140178\n",
      "153000 0.09451997007243335\n",
      "153100 0.08910036871675402\n",
      "Starting epoch 15\n",
      "153200 0.09238702254369854\n",
      "153300 0.07828363038599491\n",
      "153400 0.08063364367000758\n",
      "153500 0.08518492999486625\n",
      "153600 0.09189315903931856\n",
      "153700 0.07601185402600094\n",
      "153800 0.0841473938524723\n",
      "153900 0.08192681271582841\n",
      "154000 0.08163365972228348\n",
      "154100 0.07647427091840654\n",
      "154200 0.07352746804244817\n",
      "154300 0.08915669564157724\n",
      "154400 0.07727929425425828\n",
      "154500 0.08865908161737025\n",
      "154600 0.08928997267968952\n",
      "154700 0.0813921734970063\n",
      "154800 0.08201516849920154\n",
      "154900 0.0848391724191606\n",
      "155000 0.08643964739516377\n",
      "155100 0.08590937588363885\n",
      "155200 0.0876142338756472\n",
      "155300 0.09034185597673058\n",
      "155400 0.08523871220648288\n",
      "155500 0.08655425069853663\n",
      "155600 0.09008188953623175\n",
      "155700 0.08838891066610813\n",
      "155800 0.08388371471315623\n",
      "155900 0.08869123453041539\n",
      "156000 0.07934270314872265\n",
      "156100 0.08797152463346719\n",
      "156200 0.09460689309984445\n",
      "156300 0.08538681119680405\n",
      "156400 0.09180150327272713\n",
      "156500 0.08529667112976312\n",
      "156600 0.08409719161689282\n",
      "156700 0.08296318413689732\n",
      "156800 0.08964202687144279\n",
      "156900 0.09043957879766822\n",
      "157000 0.09685063051059842\n",
      "157100 0.09417026905342936\n",
      "157200 0.0897507759090513\n",
      "157300 0.08916829117573798\n",
      "157400 0.08754512838087976\n",
      "157500 0.08747084314003586\n",
      "157600 0.07939231021329761\n",
      "157700 0.09093616988509894\n",
      "157800 0.09228012690320611\n",
      "157900 0.09588646134361625\n",
      "158000 0.09161916516721248\n",
      "158100 0.09162803932093083\n",
      "158200 0.09329204421490431\n",
      "158300 0.09006246476434171\n",
      "158400 0.0864248289912939\n",
      "158500 0.07919227721169592\n",
      "158600 0.083745555607602\n",
      "158700 0.08561414645984769\n",
      "158800 0.09171513088047505\n",
      "158900 0.09657978851348162\n",
      "159000 0.09907522182911635\n",
      "159100 0.09856278320774436\n",
      "159200 0.09244268340989947\n",
      "159300 0.09135907592251896\n",
      "159400 0.09942789256572723\n",
      "159500 0.08556974963285029\n",
      "159600 0.09308151643723249\n",
      "159700 0.08614181804936379\n",
      "159800 0.0853344465047121\n",
      "159900 0.09739858624525369\n",
      "160000 0.085709020299837\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.968483361774744\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9520237880939523\n",
      "Saving checkpoint to data/model/film.pt\n",
      "160100 0.08677357049658894\n",
      "160200 0.08739899968728423\n",
      "160300 0.08324250275734812\n",
      "160400 0.09363989999517798\n",
      "160500 0.08975961687043309\n",
      "160600 0.09196344453841448\n",
      "160700 0.09507211139425635\n",
      "160800 0.09513423541560768\n",
      "160900 0.10463390912860632\n",
      "161000 0.08700475443154573\n",
      "161100 0.0864113363996148\n",
      "161200 0.09355929426848889\n",
      "161300 0.09015649043023587\n",
      "161400 0.08147069837898016\n",
      "161500 0.09164225980639458\n",
      "161600 0.08747598551213741\n",
      "161700 0.08494915135204792\n",
      "161800 0.08570509258192033\n",
      "161900 0.08863239257596434\n",
      "162000 0.09313238022848963\n",
      "162100 0.09234762952663005\n",
      "162200 0.08920931613072752\n",
      "162300 0.09044384406879544\n",
      "162400 0.10208319552242756\n",
      "162500 0.09113686790689826\n",
      "162600 0.08924056557007135\n",
      "162700 0.09481097619049252\n",
      "162800 0.08737680695950985\n",
      "162900 0.08518434979952871\n",
      "163000 0.09026241417042911\n",
      "163100 0.08816247563809157\n",
      "163200 0.08370259941555559\n",
      "163300 0.0858969787042588\n",
      "163400 0.09348223363980651\n",
      "163500 0.08727278687059879\n",
      "163600 0.09363023551180959\n",
      "163700 0.08960927094332874\n",
      "163800 0.0934994176030159\n",
      "163900 0.10136447129771113\n",
      "164000 0.09656149988994002\n",
      "Starting epoch 16\n",
      "164100 0.09138174175284802\n",
      "164200 0.0770751410908997\n",
      "164300 0.07867941789329053\n",
      "164400 0.07829665953759105\n",
      "164500 0.07053741047158837\n",
      "164600 0.08357995694503188\n",
      "164700 0.06942456854507327\n",
      "164800 0.08520933791995049\n",
      "164900 0.08910785976797342\n",
      "165000 0.07494692877866328\n",
      "165100 0.07680431329645217\n",
      "165200 0.07531522654462605\n",
      "165300 0.0791911055520177\n",
      "165400 0.0734294298198074\n",
      "165500 0.08378836609888822\n",
      "165600 0.08097391947172582\n",
      "165700 0.08175477294251322\n",
      "165800 0.07607873626053334\n",
      "165900 0.07431809889152646\n",
      "166000 0.09067677287384868\n",
      "166100 0.08524960856884718\n",
      "166200 0.08894878881983459\n",
      "166300 0.09055625014007092\n",
      "166400 0.0860629017278552\n",
      "166500 0.07764897042885423\n",
      "166600 0.0787094350811094\n",
      "166700 0.08731140587013214\n",
      "166800 0.08747478960081935\n",
      "166900 0.0727640332467854\n",
      "167000 0.08407173583284021\n",
      "167100 0.08412720080465079\n",
      "167200 0.08557353210635484\n",
      "167300 0.08154539507813752\n",
      "167400 0.07921746473759413\n",
      "167500 0.08963097093626857\n",
      "167600 0.08425114036537706\n",
      "167700 0.0821656334400177\n",
      "167800 0.07516325704753399\n",
      "167900 0.07833879875019192\n",
      "168000 0.07806702994741499\n",
      "168100 0.08464418936520815\n",
      "168200 0.0845881516765803\n",
      "168300 0.08453109078109264\n",
      "168400 0.08276414926163853\n",
      "168500 0.08120206445455551\n",
      "168600 0.0831548014562577\n",
      "168700 0.07985815100837498\n",
      "168800 0.08085715193301439\n",
      "168900 0.08329475555103272\n",
      "169000 0.08762030294165016\n",
      "169100 0.09205577556975186\n",
      "169200 0.08203111345879734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169300 0.09220461209304631\n",
      "169400 0.08146116396412253\n",
      "169500 0.08091684962622821\n",
      "169600 0.08358662397600711\n",
      "169700 0.07746471489779651\n",
      "169800 0.08493642856366933\n",
      "169900 0.09565877571702003\n",
      "170000 0.09397998841479421\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9672501599829352\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9505503663553146\n",
      "Saving checkpoint to data/model/film.pt\n",
      "170100 0.09028957479167729\n",
      "170200 0.07818520681932568\n",
      "170300 0.08212458987720311\n",
      "170400 0.09516641262918711\n",
      "170500 0.09218353039585053\n",
      "170600 0.09445692034438252\n",
      "170700 0.07811483349651098\n",
      "170800 0.08499275982379913\n",
      "170900 0.08320409415289759\n",
      "171000 0.09208363432437182\n",
      "171100 0.09031467009335756\n",
      "171200 0.08693029788322747\n",
      "171300 0.08201767152175307\n",
      "171400 0.08774013165384531\n",
      "171500 0.09188549092039466\n",
      "171600 0.093754405179061\n",
      "171700 0.0945151313394308\n",
      "171800 0.08654758001677693\n",
      "171900 0.08239482209086418\n",
      "172000 0.0864716727938503\n",
      "172100 0.08890001008287073\n",
      "172200 0.08382580539211631\n",
      "172300 0.07812584790401161\n",
      "172400 0.08559676322154701\n",
      "172500 0.08410896059125662\n",
      "172600 0.07693722302094103\n",
      "172700 0.08693271456286311\n",
      "172800 0.09536295607686043\n",
      "172900 0.08500605089589953\n",
      "173000 0.08530920878052711\n",
      "173100 0.08460922973230481\n",
      "173200 0.0810054088011384\n",
      "173300 0.08672361394390464\n",
      "173400 0.08698724554851651\n",
      "173500 0.09116304309107363\n",
      "173600 0.07923199385404586\n",
      "173700 0.10270082930102944\n",
      "173800 0.08347160361707211\n",
      "173900 0.09147688379511237\n",
      "174000 0.08871938702650368\n",
      "174100 0.08589117359369994\n",
      "174200 0.0893933753669262\n",
      "174300 0.08232840916141868\n",
      "174400 0.09100460761226714\n",
      "174500 0.088290423322469\n",
      "174600 0.09599814618006348\n",
      "174700 0.09028663385193796\n",
      "174800 0.08959771549329161\n",
      "174900 0.09173125018365681\n",
      "175000 0.09310632724314928\n",
      "Starting epoch 17\n",
      "175100 0.07606069703586399\n",
      "175200 0.06180706924758852\n",
      "175300 0.07682926093693823\n",
      "175400 0.06893376746214926\n",
      "175500 0.0682425946276635\n",
      "175600 0.06643886567093432\n",
      "175700 0.08040386946871876\n",
      "175800 0.0783132182713598\n",
      "175900 0.07420666256919503\n",
      "176000 0.07336817083880305\n",
      "176100 0.07298820200376213\n",
      "176200 0.08402940376661718\n",
      "176300 0.0873038505204022\n",
      "176400 0.07042188837192953\n",
      "176500 0.07671604511328041\n",
      "176600 0.08551786029711365\n",
      "176700 0.07917814407497645\n",
      "176800 0.07421833503060044\n",
      "176900 0.0752899019792676\n",
      "177000 0.07375205553136766\n",
      "177100 0.07690111109986901\n",
      "177200 0.07481021028012037\n",
      "177300 0.06692983432672918\n",
      "177400 0.08589737609028816\n",
      "177500 0.07118897608481348\n",
      "177600 0.0817609208356589\n",
      "177700 0.07944031522609293\n",
      "177800 0.08087580865249037\n",
      "177900 0.08162078984081746\n",
      "178000 0.07852685422636568\n",
      "178100 0.08806188840419055\n",
      "178200 0.0829782130010426\n",
      "178300 0.07636009076610208\n",
      "178400 0.0839759327750653\n",
      "178500 0.08643408067990094\n",
      "178600 0.08538337976671756\n",
      "178700 0.08316143079660833\n",
      "178800 0.07900607948191464\n",
      "178900 0.07827614265959709\n",
      "179000 0.08059207019396127\n",
      "179100 0.07732469598762691\n",
      "179200 0.0877050401084125\n",
      "179300 0.07989201091229915\n",
      "179400 0.08244174624793231\n",
      "179500 0.07891309011727571\n",
      "179600 0.0851106443721801\n",
      "179700 0.08632235730066895\n",
      "179800 0.07613138342276216\n",
      "179900 0.07210727277677506\n",
      "180000 0.09145948834717274\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9739961070819113\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.95689074677814\n",
      "Saving checkpoint to data/model/film.pt\n",
      "180100 0.08090666441246867\n",
      "180200 0.08091444556601346\n",
      "180300 0.08487956009805203\n",
      "180400 0.0799205783661455\n",
      "180500 0.08095359799452126\n",
      "180600 0.08499198578763753\n",
      "180700 0.08751636847853661\n",
      "180800 0.08344863156788052\n",
      "180900 0.08679797464981676\n",
      "181000 0.08484773635864258\n",
      "181100 0.08742127652280032\n",
      "181200 0.0777762458845973\n",
      "181300 0.07957072423771024\n",
      "181400 0.08480613272637129\n",
      "181500 0.07518666711635888\n",
      "181600 0.08050358621403575\n",
      "181700 0.08725881334394217\n",
      "181800 0.08408990770578384\n",
      "181900 0.08534822771325708\n",
      "182000 0.07387167314067483\n",
      "182100 0.0993586899433285\n",
      "182200 0.08468128506094218\n",
      "182300 0.08828197776339948\n",
      "182400 0.07953065212816\n",
      "182500 0.08281442109495402\n",
      "182600 0.08681918035261332\n",
      "182700 0.08971709839999675\n",
      "182800 0.08488993747159838\n",
      "182900 0.08564792092889548\n",
      "183000 0.07898495728615672\n",
      "183100 0.08409473239444196\n",
      "183200 0.08010326074436307\n",
      "183300 0.08254033097065985\n",
      "183400 0.08154749980196357\n",
      "183500 0.07390621345490217\n",
      "183600 0.09325535570736974\n",
      "183700 0.08370073822326958\n",
      "183800 0.09220172671135515\n",
      "183900 0.08441791353281587\n",
      "184000 0.08857571155764163\n",
      "184100 0.08554969049990177\n",
      "184200 0.08858928001485765\n",
      "184300 0.08466277497820557\n",
      "184400 0.08368982745334506\n",
      "184500 0.07658032300882041\n",
      "184600 0.07695808141492307\n",
      "184700 0.08417188910767436\n",
      "184800 0.09101551730185747\n",
      "184900 0.07769587567076087\n",
      "185000 0.08477004766464233\n",
      "185100 0.07857496050186455\n",
      "185200 0.08424704058095812\n",
      "185300 0.0853836077824235\n",
      "185400 0.08781054209917784\n",
      "185500 0.07971115325577557\n",
      "185600 0.08312115457374603\n",
      "185700 0.07635007434058934\n",
      "185800 0.08001494259573519\n",
      "185900 0.08894291980192065\n",
      "Starting epoch 18\n",
      "186000 0.07389120833016932\n",
      "186100 0.06998857259750366\n",
      "186200 0.0666126870457083\n",
      "186300 0.06361689036712051\n",
      "186400 0.06986077666282654\n",
      "186500 0.0730512584419921\n",
      "186600 0.06740076149813831\n",
      "186700 0.07216433848254383\n",
      "186800 0.06532574607990682\n",
      "186900 0.07126586330123245\n",
      "187000 0.06616585898213088\n",
      "187100 0.06660649875178933\n",
      "187200 0.0774955980759114\n",
      "187300 0.08706810140050948\n",
      "187400 0.06936664934270084\n",
      "187500 0.08110013660043477\n",
      "187600 0.07859398849308491\n",
      "187700 0.07314070018939674\n",
      "187800 0.09278166377916933\n",
      "187900 0.08457680847961456\n",
      "188000 0.07543437635526061\n",
      "188100 0.07363893693778664\n",
      "188200 0.07648867127485573\n",
      "188300 0.07235325563699008\n",
      "188400 0.07397867168299854\n",
      "188500 0.0789114587334916\n",
      "188600 0.07780511229299009\n",
      "188700 0.07678765615448356\n",
      "188800 0.07233200944028795\n",
      "188900 0.07085723099764436\n",
      "189000 0.07453545920550823\n",
      "189100 0.07988560108933598\n",
      "189200 0.07022475510835648\n",
      "189300 0.07976770862936973\n",
      "189400 0.06477271567098797\n",
      "189500 0.06957014079205692\n",
      "189600 0.07033471531234682\n",
      "189700 0.0873116900678724\n",
      "189800 0.07289944602642208\n",
      "189900 0.07707028720527888\n",
      "190000 0.07851807797327638\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9708431100682594\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9543239261022328\n",
      "Saving checkpoint to data/model/film.pt\n",
      "190100 0.07133225821424276\n",
      "190200 0.07048519649542868\n",
      "190300 0.0776894936338067\n",
      "190400 0.07317102805245668\n",
      "190500 0.0831746975146234\n",
      "190600 0.08275420427322387\n",
      "190700 0.07511708985082804\n",
      "190800 0.08183843763545155\n",
      "190900 0.07787244530394673\n",
      "191000 0.08036811308003962\n",
      "191100 0.07518740659579634\n",
      "191200 0.07797729001380503\n",
      "191300 0.07499264289624989\n",
      "191400 0.07996430935338139\n",
      "191500 0.07568578344769776\n",
      "191600 0.08560307091102004\n",
      "191700 0.07518119486048817\n",
      "191800 0.07959002474322915\n",
      "191900 0.08659301082603633\n",
      "192000 0.07280669479630887\n",
      "192100 0.07908827798441052\n",
      "192200 0.0772737292572856\n",
      "192300 0.08617830164730549\n",
      "192400 0.08762611193582416\n",
      "192500 0.08036014153622091\n",
      "192600 0.08245603023096919\n",
      "192700 0.07810437617823482\n",
      "192800 0.09066083028912544\n",
      "192900 0.07403886271640658\n",
      "193000 0.07719527256675064\n",
      "193100 0.07601685838773847\n",
      "193200 0.0932961125858128\n",
      "193300 0.08598094046115876\n",
      "193400 0.0840045553818345\n",
      "193500 0.08328907053917646\n",
      "193600 0.08344611051492393\n",
      "193700 0.07451011495664715\n",
      "193800 0.07546495297923685\n",
      "193900 0.0802178379893303\n",
      "194000 0.07145605930127204\n",
      "194100 0.08362530341371893\n",
      "194200 0.07891169507987797\n",
      "194300 0.0730984430713579\n",
      "194400 0.07712488486431539\n",
      "194500 0.07945220405235887\n",
      "194600 0.07924753910861909\n",
      "194700 0.08313169779255986\n",
      "194800 0.0785034739645198\n",
      "194900 0.07839541072025895\n",
      "195000 0.0851708878390491\n",
      "195100 0.08414171383716167\n",
      "195200 0.08470813740044832\n",
      "195300 0.08508306826464831\n",
      "195400 0.09421469602733851\n",
      "195500 0.08029635165818036\n",
      "195600 0.08308007385581732\n",
      "195700 0.07079240282066167\n",
      "195800 0.07779968140646815\n",
      "195900 0.07779320877976716\n",
      "196000 0.07807792657986283\n",
      "196100 0.07338426357135176\n",
      "196200 0.0691854041814804\n",
      "196300 0.0872435111925006\n",
      "196400 0.08231725115329028\n",
      "196500 0.08199595188722014\n",
      "196600 0.08380618954077362\n",
      "196700 0.08047593079507351\n",
      "196800 0.08899020944721997\n",
      "Starting epoch 19\n",
      "196900 0.07727885113563389\n",
      "197000 0.06565336977597326\n",
      "197100 0.06680329732364043\n",
      "197200 0.06777579495683313\n",
      "197300 0.05840798395685851\n",
      "197400 0.06985319590196014\n",
      "197500 0.06552385418210178\n",
      "197600 0.0704319473914802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197700 0.07250388925895095\n",
      "197800 0.07114667549263685\n",
      "197900 0.06939426633529365\n",
      "198000 0.06605281137395651\n",
      "198100 0.07379705478437244\n",
      "198200 0.07357056269422174\n",
      "198300 0.07678444199264049\n",
      "198400 0.06968452059663832\n",
      "198500 0.07455255946144462\n",
      "198600 0.06935762471985071\n",
      "198700 0.07282221641391516\n",
      "198800 0.07011267272755503\n",
      "198900 0.07249952682293952\n",
      "199000 0.0709448839025572\n",
      "199100 0.07238747478462755\n",
      "199200 0.0710337765701115\n",
      "199300 0.0689069044496864\n",
      "199400 0.07450036059133708\n",
      "199500 0.07080773970112204\n",
      "199600 0.06698649447411299\n",
      "199700 0.0754755724966526\n",
      "199800 0.07020645442418755\n",
      "199900 0.0798599299811758\n",
      "200000 0.07467276642099023\n",
      "Checking training accuracy ... \n",
      "train accuracy is 0.9714363801194539\n",
      "Checking validation accuracy ...\n",
      "val accuracy is  0.9545172710362622\n",
      "Saving checkpoint to data/model/film.pt\n"
     ]
    }
   ],
   "source": [
    "stats = train_loop(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0468fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_local_copies == 1 and cleanup_local_copies == 1:\n",
    "    os.remove('/tmp/train_questions.h5')\n",
    "    os.remove('/tmp/train_features.h5')\n",
    "    os.remove('/tmp/val_questions.h5')\n",
    "    os.remove('/tmp/val_features.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78777abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/stats/stats.json\", \"w\") as outfile:\n",
    "    json.dump(stats, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c740c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = json.load(open(\"data/stats/stats.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18e7b6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = '#d62728'\n",
    "ax1.plot(np.arange(len(stats['train_accs'])) * checkpoint_every + checkpoint_every,\n",
    "         stats['train_accs'], color=color, alpha=0.6, label='train acc')\n",
    "ax1.plot(np.arange(len(stats['val_accs'])) * checkpoint_every + checkpoint_every,\n",
    "         stats['val_accs'], linestyle='--', alpha=0.6, color=color, label='val acc')\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('accuracy', color=color)\n",
    "ax1.legend(loc='center right')\n",
    "\n",
    "color = '#1f77b4'\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.arange(len(stats['train_losses'])) * record_loss_every,\n",
    "         stats['train_losses'], color=color, alpha=0.6, label='train loss')\n",
    "ax2.set_ylabel('loss', color=color)\n",
    "ax2.legend(loc='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('data/stats/imgs/curves.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29a4a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95689074677814\n"
     ]
    }
   ],
   "source": [
    "print(stats['best_val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c705e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
